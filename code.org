
#+PROPERTY: header-args:bash+ :comments both :noweb yes :eval no-export
#+PROPERTY: header-args:bash+ :session (concat "*" (file-name-sans-extension (buffer-name)) "-shell*")
#+PROPERTY: header-args:bash+ :tangle-mode (identity #o544) :shebang #!/usr/bin/env bash
#+PROPERTY: header-args:jupyter-python :kernel TMB :session TMB

* ROIs

ROI refers both to the citet:zwally_2012 sectors and the citet:mouginot_2019_glacier basins and regions.

Procedure to map the ROIs to the SMB grids:
+ ROIs are in EPSG:4326 projection, and need to be re-projected to the SMB projection
  + HIRHAM :: rotated pole
  + MAR :: Oblique stereographic 
  + RACMO :: EPSG:3413

SMB grids do not match ROIs perfectly. When the ROIs are larger, that is fine - whatever the SMB is in the sector interior is the modeled SMB. It is problematic where the ROIs are smaller than the model domain. Because the largest SMB losses are at the edge, if some RCM pixels are outside of a ROI and not counted, this would introduce large errors.
+ For each SMB, determine the mask
  + HIRHAM ::
  + MAR ::
  + RACMO :: No mask provided. Look at summer season and assume any cell with any values != 0 is in the model domain, and all cells summed = 0 is outside
+ For all model domain cells outside of a ROI, enlarge the ROI to include them, and join the new ROI cells to the nearest ROI cell that is inside the model domain

** Mouginot 2019

#+NAME: import_mouginot
#+BEGIN_SRC bash

log_info "Loading Mouginot 2019"

g.mapset -c Mouginot_2019

v.import input=${DATADIR}/Mouginot_2019/Greenland_Basins_PS_v1.4.2.shp output=basins snap=1

# remove peripheral ice caps
db.execute sql="DELETE FROM basins WHERE name LIKE 'ICE_CAPS_%'"

v.db.addcolumn map=basins columns="SUBREGION1_num INT,cat_ INT"

db.execute sql="UPDATE basins SET cat_=cat"

# convert NW NO NE CW CE SW SE based on clock
db.execute sql="UPDATE basins SET SUBREGION1_num=11 WHERE SUBREGION1='NW'"
db.execute sql="UPDATE basins SET SUBREGION1_num=12 WHERE SUBREGION1='NO'"
db.execute sql="UPDATE basins SET SUBREGION1_num=1 WHERE SUBREGION1='NE'"
db.execute sql="UPDATE basins SET SUBREGION1_num=3 WHERE SUBREGION1='CE'"
db.execute sql="UPDATE basins SET SUBREGION1_num=9 WHERE SUBREGION1='CW'"
db.execute sql="UPDATE basins SET SUBREGION1_num=5 WHERE SUBREGION1='SE'"
db.execute sql="UPDATE basins SET SUBREGION1_num=7 WHERE SUBREGION1='SW'"
#+END_SRC

** Zwally 2012

#+NAME: import_zwally
#+BEGIN_SRC bash

log_info "Loading Zwally 2012"

g.mapset -c Zwally_2012
v.import input=${DATADIR}/Zwally_2012/sectors output=sectors snap=1
#+END_SRC

* HIRHAM
:PROPERTIES:
:header-args:bash+: :tangle HIRHAM.sh
:END:

** Init

#+BEGIN_SRC bash :tangle no
grass -c EPSG:4326 G_HIRHAM

# from gridOBC_SD.nc
ncdump -v rlon ~/data/HIRHAM/gridOBC_SD.nc
ncdump -v rlat ~/data/HIRHAM/gridOBC_SD.nc
#+END_SRC

#+BEGIN_SRC bash
<<init_bash>>
<<init_grass>>
#+END_SRC


** Domain

#+BEGIN_SRC bash
g.region w=-13.65 e=1.3 s=-9.8 n=12.2 res=0:03
g.region w=w-0.025 e=e+0.025 s=s-0.025 n=n+0.025 -p
g.region save=RCM

g.region res=0:0.5 # ~1 km grid cell resolution
g.region save=sectors --o
#+END_SRC

*** Test 

#+BEGIN_SRC bash :tangle no
r.in.gdal -ol input=NetCDF:${DATADIR}/HIRHAM/daily/DarcySensitivity_RP810_Daily2D_GL2LIN_Darcy_60m_liqCL_wh1_smb_HydroYr_2012_2013_DM_SD.nc:smb band=200 output=smb
r.region map=smb region=RCM

v.in.ogr -o input=./dat/Zrot.gpkg output=Z
v.in.ogr -o input=./dat/Mrot.gpkg output=M

d.mon start=wx0
r.colors map=smb color=viridis
d.erase
d.rast smb
d.vect Z fill_color=none
d.vect M fill_color=none
d.grid 1:0:0
#+END_SRC


** Convert sectors to rotated pole

+ https://lists.osgeo.org/pipermail/grass-user/2011-October/062180.html
+ This no longer works in GRASS 7.8 https://lists.osgeo.org/pipermail/grass-user/2020-November/081828.html
+ Therefore, the following is done 1x in a VM (Ubuntu 18.04) running GRASS 7.4

#+BEGIN_SRC bash :results verbatim :tangle no
rm -fR Gnorm Grot

grass -c EPSG:4326 Gnorm

DATADIR=~/data

v.import input=${DATADIR}/Zwally_2012/sectors output=Z
v.import snap=1 input=${DATADIR}/Mouginot_2019/Greenland_Basins_PS_v1.4.2.shp output=M

cat << EOF > ./Gnorm/PERMANENT/PROJ_INFO
name: General Oblique Transformation
datum: wgs84
towgs84: 0.000,0.000,0.000
proj: ob_tran
o_proj: latlon
ellps: wgs84
a: 6378137.0000000000
es: 0.0066943800
f: 298.2572235630
lat_0: 0.0000000000
lon_0: 180.0000000000
o_lat_p: 18.0
o_lon_p: -200.0
EOF

# rotated_pole:grid_north_pole_latitude = 18. ;
# rotated_pole:grid_north_pole_longitude = -200.

cat << EOF > ./Gnorm/PERMANENT/PROJ_UNITS
unit: degree
units: degrees
meters: .0174532925
EOF

grass -e -c EPSG:4326 Grot
grass ./Grot/PERMANENT

v.proj location=Gnorm input=Z
v.proj location=Gnorm input=M

# g.region vector=Z,M
# d.mon start=wx0
# d.erase
# d.vect Z
# d.vect M
# d.grid 1:0:0

v.out.ogr input=Z output=./dat/Zrot.gpkg
v.out.ogr input=M output=./dat/Mrot.gpkg
#+END_SRC

** Load sectors

This should be:

#+BEGIN_SRC bash :tangle no
<<import_mouginot>>
<<import_zwally>>
#+END_SRC

But we're loading different files that have been converted to the rotated pole, so here I **duplicate** those code blocks but change the input filename.

#+BEGIN_SRC bash
log_info "Loading Zwally 2012"

g.mapset -c Zwally_2012
v.in.ogr -o input=Zwally_2012_HIRHAM.gpkg output=sectors

v.db.dropcolumn map=sectors columns="cat_"
v.db.renamecolumn map=sectors column=cat__1,cat_
#+END_SRC

#+BEGIN_SRC bash

log_info "Loading Mouginot 2019"

g.mapset -c Mouginot_2019

v.in.ogr -o input=Mouginot_2019_HIRHAM.gpkg output=basins

# remove peripheral ice caps
db.execute sql="DELETE FROM basins WHERE name LIKE 'ICE_CAPS_%'"

v.db.addcolumn map=basins columns="SUBREGION1_num INT"

# convert NW NO NE CW CE SW SE based on clock
db.execute sql="UPDATE basins SET SUBREGION1_num=11 WHERE SUBREGION1='NW'"
db.execute sql="UPDATE basins SET SUBREGION1_num=12 WHERE SUBREGION1='NO'"
db.execute sql="UPDATE basins SET SUBREGION1_num=1 WHERE SUBREGION1='NE'"
db.execute sql="UPDATE basins SET SUBREGION1_num=3 WHERE SUBREGION1='CE'"
db.execute sql="UPDATE basins SET SUBREGION1_num=9 WHERE SUBREGION1='CW'"
db.execute sql="UPDATE basins SET SUBREGION1_num=5 WHERE SUBREGION1='SE'"
db.execute sql="UPDATE basins SET SUBREGION1_num=7 WHERE SUBREGION1='SW'"

g.mapset PERMANENT
#+END_SRC
 

** Find model ice domain

+ Use all cells != 0 for sum of 2020 JAS as model domain

#+BEGIN_SRC bash
r.in.gdal -ol input="NetCDF:${DATADIR}/HIRHAM/ZwallyMasks_all_SD.nc:glacmask" output=mask
r.region map=mask region=RCM
r.mapcalc "mask_ice_all = if(mask == 1, 1, null())"

r.clump input=mask_ice_all output=mask_ice_clump
main_clump=$(r.stats -c -n mask_ice_clump sort=desc | head -n1 | cut -d" " -f1)
r.mapcalc "mask_ice = if(mask_ice_clump == ${main_clump}, 1, null())"
#+END_SRC

** Expand sectors to cover model domain

We'll develop this here on the HIRHAM data 1x, but do so generically so that when working with MAR and RACMO we can just <<expand_sectors>>. The one requirement is that we expect a "mask_ice" raster in the PERMANENT mapset which defines the ice domain.

#+NAME: expand_sectors
#+BEGIN_SRC bash :tangle no
<<expand_zwally>>
<<expand_mouginot>>
#+END_SRC

*** Zwally

#+NAME: expand_zwally
#+BEGIN_SRC bash

log_info "Expanding Zwally sectors to cover RCM domain"

g.mapset Zwally_2012
g.region region=sectors

v.to.rast input=sectors output=sectors use=attr attribute_column=cat_
# r.mapcalc "outside = if(isnull(sectors) & not(isnull(mask_ice)), 1, null())"

# Works fine if limited to contiguous cells (hence main_clump).
# Deosn't work great for distal islands (e.g. NE GL).
# Probably need to jump to v.distance or r.distance if we want to assign these to sectors.
r.grow.distance input=sectors value=value
r.mapcalc "sectors_e = if(mask_ice, int(value), null())" # sectors_enlarged
r.to.vect input=sectors_e output=sectors_e type=area
#+END_SRC


*** Mouginot

#+NAME: expand_mouginot
#+BEGIN_SRC bash

log_info "Expanding Mouginot basins to cover RCM domain"

g.mapset Mouginot_2019
g.region region=sectors

v.to.rast input=basins output=basins use=attr attribute_column=cat_ labelcolumn=SUBREGION1
# r.mapcalc "outside = if(isnull(basins) & mask_ice, 1, null())"
r.grow.distance input=basins value=value_b
r.mapcalc "basins_e = if(mask_ice, int(value_b), null())"
r.category map=basins separator=":" > ./tmp/basins_cats
r.category map=basins_e separator=":" rules=./tmp/basins_cats
r.to.vect input=basins_e output=basins_e type=area

v.to.rast input=basins output=regions use=attr attribute_column=SUBREGION1_num labelcolumn=SUBREGION1
# r.mapcalc "outside = if(isnull(regions) & mask_ice, 1, null())"
r.grow.distance input=regions value=value_r
r.mapcalc "regions_e = if(mask_ice, int(value_r), null())"
r.category map=regions separator=":" > ./tmp/region_cats
r.category map=regions_e separator=":" rules=./tmp/region_cats
r.to.vect input=regions_e output=regions_e type=area
#+END_SRC

** Test location alignment

#+BEGIN_SRC bash :tangle no
grass ./G_HIRHAM/PERMANENT
g.mapset PERMANENT
d.mon start=wx0
d.erase

d.rast mask_ice
# d.vect basins@Mouginot_2019 fill_color=none
# d.vect sectors@Zwally_2012 fill_color=none

d.rast sectors_e@Zwally_2012
d.rast basins_e@Mouginot_2019
d.rast regions_e@Mouginot_2019
#+END_SRC

#+RESULTS:




* MAR
:PROPERTIES:
:header-args:bash+: :tangle MAR.sh
:END:
** Init

#+BEGIN_SRC bash
<<init_bash>>
<<init_grass>>
#+END_SRC

** INFO MAR projection

From XF:

#+BEGIN_QUOTE
These outputs are on the MAR native grid using a Stereographic Oblique Projection with 70.5°N, 40°W as center.
#+END_QUOTE

Find domain boundary

#+BEGIN_QUOTE
Y21_155 and X12_84 are the X/Y axis from MAR after a selection by NOAA FERRET of a smaller domain covering Greenland only within the MAR initial integration domain. The centre of the projection in the reduced grid corresponds to the pixel (39,60).

The dimension of the original grid is 95 x 165 and the centre of the projection is the pixel (50,80). I'm not a specialist of the projections and I can't help to resolve your problem. But as it comes from a old Fortran code into, it is likely that there are some errors explaining the differences you have.
#+END_QUOTE

** Set up GRASS location

#+BEGIN_SRC bash
# update region from XY to the following proj4 string
g.proj -c proj4="+proj=sterea +lat_0=90 +lat_ts=70.5 +lon_0=-40 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs"
1
C=$(m.proj -i coordinates=-40,70.5) # center of center grid cell
echo "${C}" ## 0.00|-2198452.92|0.00
# The following numbers come from $c(y) and the X12_84 and Y21_155 arrays in the MAR NetCDF files
g.region e=680000 w=-760000 s=$(( -1180000 - 2198452 )) n=$(( 1500000 - 2198452 )) rows=134 cols=72 -pl
g.region e=e+10000 w=w-10000 s=s-10000 n=n+10000 -pl # adjust from cell center to edges
g.region save=RCM

g.region res=1000 -p
g.region save=sectors
#+END_SRC

** Ice mask
#+BEGIN_SRC bash
r.external -o source=NetCDF:${DATADIR}/MAR/daily/MARv3.11-20km-daily-NCEP-NCARv1-2000.nc:MSK output=mask
r.region map=mask region=RCM
r.colors map=mask color=haxby

# r.mapcalc "mask_ice_all = if(mask == 0, null(), 1)"
r.mapcalc "mask_ice_1 = if(mask >= 50, 1, null())"
r.grow input=mask_ice_1 output=mask_ice_all radius=3 new=1

r.clump input=mask_ice_all output=mask_clump
main_clump=$(r.stats -c -n mask_clump sort=desc | head -n1 | cut -d" " -f1)
r.mapcalc "mask_ice = if((mask_clump == ${main_clump}) & (mask > 0.5), 1, null())"
#+END_SRC

** Sectors

#+BEGIN_SRC bash
<<import_zwally>>
<<expand_zwally>>

<<import_mouginot>>
<<expand_mouginot>>

g.mapset PERMANENT
#+END_SRC

** Test location alignment

#+BEGIN_SRC bash :tangle no
grass ./G_MAR/PERMANENT
g.mapset PERMANENT
d.mon start=wx0
d.erase

d.rast mask_ice
# d.vect basins@Mouginot_2019 fill_color=none
# d.vect sectors@Zwally_2012 fill_color=none

d.rast sectors_e@Zwally_2012
d.rast basins_e@Mouginot_2019
d.rast regions_e@Mouginot_2019
#+END_SRC

#+RESULTS:



* RACMO
:PROPERTIES:
:header-args:bash+: :tangle RACMO.sh
:END:

** Set up GRASS location

#+BEGIN_SRC bash
<<init_bash>>
<<init_grass>>
#+END_SRC

#+BEGIN_SRC bash :tangle no
cdo -sinfo ${DATADIR}/RACMO/daily/smb_rec.2020_JAS.BN_RACMO2.3p2_ERA5_3h_FGRN055.1km.DD.nc
# x : -638956 to 856044 by 1000 km
# y : -3354596 to -655596 by 1000 km
#+END_SRC

#+BEGIN_SRC bash
g.region w=-638956 e=856044 s=-3354596 n=-655596 res=1000 -p
g.region n=n+500 s=s-500 w=w-500 e=e+500 res=1000 -p
g.region save=RCM

g.region res=1000 -p
g.region save=sectors
#+END_SRC

** Ice mask
#+BEGIN_SRC bash
r.external -o source=NetCDF:${DATADIR}/RACMO/Icemask_Topo_Iceclasses_lon_lat_average_1km.nc:Promicemask output=mask
r.region map=mask region=RCM
r.colors map=mask color=haxby

r.mapcalc "mask_ice_all = if(mask >= 2, 1, null())"

r.clump input=mask_ice_all output=mask_clump
main_clump=$(r.stats -c -n mask_clump sort=desc | head -n1 | cut -d" " -f1)
r.mapcalc "mask_ice = if((mask_clump == ${main_clump}) & (mask > 0.5), 1, null())"
#+END_SRC

** Reproject sectors to RCM grid

+ Nothing to do here because RACMO on EPSG:3413 projection.

** Sectors

#+BEGIN_SRC bash
<<import_zwally>>
<<expand_zwally>>

<<import_mouginot>>
<<expand_mouginot>>

g.mapset PERMANENT
#+END_SRC

** Test location alignment

#+BEGIN_SRC bash :tangle no
grass ./G_RACMO/PERMANENT
g.mapset PERMANENT
d.mon start=wx0
d.erase

d.rast mask_ice
# d.vect basins@Mouginot_2019 fill_color=none
# d.vect sectors@Zwally_2012 fill_color=none

d.rast sectors_e@Zwally_2012
d.rast basins_e@Mouginot_2019
d.rast regions_e@Mouginot_2019
#+END_SRC

#+RESULTS:




* SMB to ROIs
** Print dates

#+BEGIN_SRC jupyter-python :tangle nc_dates.py
import xarray as xr
import sys

f = sys.argv[1]

ds = xr.open_dataset(f)

if 'time' in ds.variables:
    tvar = 'time'
if 'TIME' in ds.variables:
    tvar = 'TIME'
    
t = [(str(_)[0:10]) for _ in ds[tvar].values]
for _ in t: print(_)
#+END_SRC

** HIRHAM

#+BEGIN_SRC bash :results verbatim :tangle SMB_HIRHAM_ROI.sh
<<init_bash>>

RCM=HIRHAM
mkdir -p tmp/${RCM}

dir=${DATADIR}/${RCM}/daily
f=$(ls ${dir}/*.nc|head -n1) # debug

for f in ${dir}/*.nc; do
  dates=$(python ./nc_dates.py ${f})
  band=0
  d=1985-09-01 # debug
  for d in ${dates}; do
    band=$(( ${band} + 1 ))

    log_info "HIRHAM: ${d}"

    if [[ -e ./tmp/${RCM}/sector_${d}.bsv ]]; then continue; fi

    var=smb
    if [[ ${f} == *"SMBmodel"* ]]; then var=gld; fi

    r.in.gdal -ol input="NetCDF:${f}:${var}" band=${band} output=smb --o --q
    r.region map=smb region=RCM
    
    r.univar -t --q map=smb zones=sectors_e@Zwally_2012 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/${RCM}/sector_${d}.bsv

    r.univar -t --q map=smb zones=regions_e@Mouginot_2019 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/${RCM}/region_${d}.bsv

    r.univar -t --q map=smb zones=basins_e@Mouginot_2019 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/${RCM}/basin_${d}.bsv
    
  done
done

log_info "HIRHAM ROI areas"
r.in.gdal -ol input="NetCDF:${DATADIR}/HIRHAM/ZwallyMasks_all_SD.nc:cellarea" output=area
r.region map=area region=RCM

r.univar -t --q map=area zones=sectors_e@Zwally_2012 \
| cut -d"|" -f1,13 \
| datamash -t"|" transpose \
| sed s/^sum/${d}/ \
> ./tmp/HIRHAM_sector_area.bsv

r.univar -t --q map=area zones=basins_e@Mouginot_2019 \
| cut -d"|" -f1,13 \
| datamash -t"|" transpose \
| sed s/^sum/${d}/ \
> ./tmp/HIRHAM_basin_area.bsv

r.univar -t --q map=area zones=regions_e@Mouginot_2019 \
| cut -d"|" -f1,13 \
| datamash -t"|" transpose \
| sed s/^sum/${d}/ \
> ./tmp/HIRHAM_region_area.bsv
#+END_SRC

** MAR
#+BEGIN_SRC bash :results verbatim :tangle SMB_MAR_ROI.sh

<<init_bash>>

RCM=MAR
mkdir -p tmp/${RCM}

dir=${DATADIR}/MAR/daily
f=$(ls ${dir}/MARv3.11*.nc|head -n1) # debug

for f in ${dir}/MARv3.11*.nc; do
  dates=$(python ./nc_dates.py ${f})
  band=0
  d=1986-01-01 # debug
  for d in ${dates}; do
    band=$(( ${band} + 1 ))

    log_info "MAR: ${d}"

    if [[ -e ./tmp/${RCM}/sector_${d}.bsv ]]; then continue; fi

    r.in.gdal -o input="NetCDF:${f}:SMB" band=${band} output=smb_raw --o --q
    r.region map=smb_raw region=RCM
    r.mapcalc "smb = if(mask > 50, smb_raw * (mask/100), null())" --o

    r.univar -t --q map=smb zones=sectors_e@Zwally_2012 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/${RCM}/sector_${d}.bsv

    r.univar -t --q map=smb zones=regions_e@Mouginot_2019 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/${RCM}/region_${d}.bsv

    r.univar -t --q map=smb zones=basins_e@Mouginot_2019 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/${RCM}/basin_${d}.bsv
    
  done
done


log_info "MAR ROI areas"
r.in.gdal -o input="NetCDF:${DATADIR}/MAR/daily/MAR_basins.nc:AREA" output=area
r.region map=area region=RCM

r.univar -t --q map=area zones=sectors_e@Zwally_2012 \
| cut -d"|" -f1,13 \
| datamash -t"|" transpose \
| sed s/^sum/${d}/ \
> ./tmp/MAR_sector_area.bsv

r.univar -t --q map=area zones=basins_e@Mouginot_2019 \
| cut -d"|" -f1,13 \
| datamash -t"|" transpose \
| sed s/^sum/${d}/ \
> ./tmp/MAR_basin_area.bsv

r.univar -t --q map=area zones=regions_e@Mouginot_2019 \
| cut -d"|" -f1,13 \
| datamash -t"|" transpose \
| sed s/^sum/${d}/ \
> ./tmp/MAR_region_area.bsv

#+END_SRC


** RACMO
#+BEGIN_SRC bash :results verbatim :tangle SMB_RACMO_ROI.sh

<<init_bash>>

RCM=RACMO
mkdir -p tmp/${RCM}

dir=${DATADIR}/${RCM}/daily
f=$(ls ${dir}/*.nc|head -n1) # debug

for f in ${dir}/*.nc; do
  dates=$(python ./nc_dates.py ${f})
  band=0
  d=1989-07-01 # debug
  for d in ${dates}; do
    band=$(( ${band} + 1 ))

    log_info "RACMO: ${d}"

    if [[ -e ./tmp/${RCM}/sector_${d}.bsv ]]; then continue; fi

    var=SMB_rec
    if [[ ${f} == *"ERA5"* ]]; then var=smb_rec; fi

    r.in.gdal -o input="NetCDF:${f}:${var}" band=${band} output=smb --o  --q
    r.region map=smb region=RCM

    r.univar -t --q map=smb zones=sectors_e@Zwally_2012 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/${RCM}/sector_${d}.bsv

    r.univar -t --q map=smb zones=regions_e@Mouginot_2019 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/${RCM}/region_${d}.bsv
    
    r.univar -t --q map=smb zones=basins_e@Mouginot_2019 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/${RCM}/basin_${d}.bsv

  done
done


# log_info "RACMO ROI areas"
# r.in.gdal -o input="NetCDF:${DATADIR}/MAR/daily/MAR_basins.nc:AREA" output=area
# r.region map=area region=RCM

# r.univar -t --q map=area zones=sectors_e@Zwally_2012 \
# | cut -d"|" -f1,13 \
# | datamash -t"|" transpose \
# | sed s/^sum/${d}/ \
# > ./tmp/MAR_sector_area.bsv

# r.univar -t --q map=area zones=basins_e@Mouginot_2019 \
# | cut -d"|" -f1,13 \
# | datamash -t"|" transpose \
# | sed s/^sum/${d}/ \
# > ./tmp/MAR_basin_area.bsv

# r.univar -t --q map=area zones=regions_e@Mouginot_2019 \
# | cut -d"|" -f1,13 \
# | datamash -t"|" transpose \
# | sed s/^sum/${d}/ \
# > ./tmp/MAR_region_area.bsv
	
#+END_SRC


** Create data file
*** Merge from daily to single file for each RCM and ROI

#+BEGIN_SRC bash :tangle smb_merge.sh
<<init_bash>>

for RCM in HIRHAM MAR RACMO; do
  for ROI in sector region basin; do
    log_info ${RCM} ${ROI}
    head -n1 ./tmp/${RCM}/${ROI}_2000-01-01.bsv > ./tmp/${RCM}_${ROI}.bsv
    tail -q -n1 ./tmp/${RCM}/${ROI}_*.bsv >> ./tmp/${RCM}_${ROI}.bsv
  done
done
#+END_SRC

#+RESULTS:

*** BSV to NetCDF

For HIRHAM, resolution is in degrees not meters.
+ 1 degree of latitude @ equator is 110574 m => 0.5 minutes or 0:30 seconds or 0.008333 degrees = 0.008333 * 110574 = 921.413142
+ 1 degree of latitude @ 10 °N is 110608 m => 110608 * 0.0083333 = 921.7296464 m

#+NAME: smb_bsv2nc
#+BEGIN_SRC jupyter-python :tangle smb_bsv2nc.py
import pandas as pd
import xarray as xr
import numpy as np
import datetime

time = pd.date_range(start = "1986-01-01",
                     end = datetime.date.today() + datetime.timedelta(days = 10),
                     freq = "D")

smb = xr.Dataset()
smb["time"] = (("time"), time)

smb["sector"] = pd.read_csv("./tmp/HIRHAM_sector.bsv", delimiter="|", nrows=0, index_col=0).columns.astype(np.int)

rstr = {11:'NW', 12:'NO', 1:'NE', 3:'CE', 9:'CW', 5:'SE', 7:'SW'}
rnum = pd.read_csv("./tmp/HIRHAM_region.bsv", delimiter="|", nrows=0, index_col=0).columns.astype(np.int)
smb["region"] = [rstr[n] for n in rnum]
smb["basin"] = pd.read_csv("./tmp/HIRHAM_basin.bsv", delimiter="|", nrows=0, index_col=0).columns.astype(np.int)

def bsv2nc(smb, bsv, dim):
    df = pd.read_csv("./tmp/" + bsv + ".bsv", delimiter="|", index_col=0, parse_dates=True).reindex(time)
    df.columns = df.columns.astype(np.int64)
    if dim == "region":
        df.columns = [rstr[n] for n in df.columns]
    missing = smb[dim].values[~pd.Series(smb[dim].values).isin(df.columns)]
    if len(missing) > 0:
        df[missing] = np.nan
        df = df.reindex(sorted(df.columns), axis=1)
 
    if 'HIRHAM' in bsv: grid = 912 * 912
    if 'RACMO' in bsv: grid = 1000 * 1000
    if 'MAR' in bsv: grid = 1000 * 1000
    #       mm->m  grid  m^3->kg  kg->Gt
    CONV = 1E-3  * grid * 1E3    / 1E12
    df = df * CONV
    
    smb[bsv] = (("time", dim), df)
    return smb

smb = bsv2nc(smb, "HIRHAM_sector", "sector")
smb = bsv2nc(smb, "HIRHAM_region", "region")
smb = bsv2nc(smb, "HIRHAM_basin", "basin")

smb = bsv2nc(smb, "MAR_sector", "sector")
smb = bsv2nc(smb, "MAR_region", "region")
smb = bsv2nc(smb, "MAR_basin", "basin")

smb = bsv2nc(smb, "RACMO_sector", "sector")
smb = bsv2nc(smb, "RACMO_region", "region")
smb = bsv2nc(smb, "RACMO_basin", "basin")

smb.to_netcdf("./tmp/smb3.nc")
#+END_SRC

#+RESULTS: smb_bsv2nc

Test:

#+BEGIN_SRC jupyter-python
import xarray as xr
ds = xr.open_dataset('./tmp/smb3.nc')
ds[['HIRHAM_sector','MAR_sector','RACMO_sector']].sum(dim='sector').to_dataframe().plot()
#+END_SRC

#+RESULTS:
: <AxesSubplot:xlabel='time'>

*** Create SMB from individual SMBs


#+BEGIN_SRC jupyter-python
import xarray as xr
ds = xr.open_dataset('./tmp/smb3.nc')

for roi in ['sector','region','basin']:
    mean = ds[['HIRHAM_'+roi, 'MAR_'+roi, 'RACMO_'+roi]].to_array(dim='m').mean('m')
    s = 'smb_' + roi
    ds[s] = mean
    
    ds[s].attrs["long_name"] = "Surface mass balance (RCM mean)"
    ds[s].attrs["standard_name"] = "land_ice_mass_tranport"
    ds[s].attrs["units"] = "Gt d-1"
    ds[s].attrs["coordinates"] = "time region"

ds['smb'] = ds['smb_sector'].sum(dim='sector')

print(ds)
ds.to_netcdf('./tmp/smb.nc')
#+END_SRC

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:        (basin: 252, region: 7, sector: 19, time: 12827)
Coordinates:
  ,* time           (time) datetime64[ns] 1986-01-01 1986-01-02 ... 2021-02-12
  ,* sector         (sector) int64 11 12 13 14 21 22 31 ... 50 61 62 71 72 81 82
  ,* region         (region) object 'NE' 'CE' 'SE' 'SW' 'CW' 'NW' 'NO'
  ,* basin          (basin) int64 1 2 3 4 5 6 7 8 ... 252 253 254 255 257 258 259
Data variables:
    HIRHAM_sector  (time, sector) float64 0.01656 0.008927 0.003158 ... nan nan
    HIRHAM_region  (time, region) float64 -0.005409 -0.01359 2.343 ... nan nan
    HIRHAM_basin   (time, basin) float64 -0.001006 -8.688e-05 ... nan nan
    MAR_sector     (time, sector) float64 0.007688 0.00143 0.001082 ... nan nan
    MAR_region     (time, region) float64 0.004342 0.007353 2.117 ... nan nan
    MAR_basin      (time, basin) float64 -0.0004718 -0.0003378 ... nan nan
    RACMO_sector   (time, sector) float64 0.01179 0.004654 0.00282 ... nan nan
    RACMO_region   (time, region) float64 0.004671 0.01214 1.851 ... nan nan nan
    RACMO_basin    (time, basin) float64 0.0004132 2.895e-05 0.01098 ... nan nan
    smb_sector     (time, sector) float64 0.01201 0.005004 0.002354 ... nan nan
    smb_region     (time, region) float64 0.001201 0.001965 2.104 ... nan nan
    smb_basin      (time, basin) float64 -0.0003547 -0.0001319 ... nan nan
    smb            (time) float64 2.347 3.202 4.224 1.591 ... 0.0 0.0 0.0 0.0
#+end_example


* MMB to ROI

Already done in each of the MMB products
+ citet:mankoff_2020_solid includes ROI for each gate
+ citet:mouginot_2019_forty is provided on Zwally sector

* BMB to ROI
:PROPERTIES:
:header-args:bash+: :tangle BMB.sh
:END:

#+BEGIN_SRC bash
<<init_bash>>
<<init_grass>>
#+END_SRC

** ROIs

Import ROIs to this location

#+BEGIN_SRC bash
g.mapset -c Mouginot_2019
r.proj -pgl location=G_RACMO mapset=Mouginot_2019
r.proj -pg location=G_RACMO mapset=Mouginot_2019 input=basins_e
eval $(r.proj -pg location=G_RACMO mapset=Mouginot_2019 input=basins_e)
g.region e=$e w=$w n=$n s=$s rows=$rows cols=$cols -p
r.proj location=G_RACMO mapset=Mouginot_2019 input=basins_e
r.proj location=G_RACMO mapset=Mouginot_2019 input=regions_e

g.mapset -c Zwally_2012
r.proj -pgl location=G_RACMO mapset=Zwally_2012
r.proj -pg location=G_RACMO mapset=Zwally_2012 input=sectors_e
eval $(r.proj -pg location=G_RACMO mapset=Zwally_2012 input=sectors_e)
g.region e=$e w=$w n=$n s=$s rows=$rows cols=$cols -p
r.proj location=G_RACMO mapset=Zwally_2012 input=sectors_e
#+END_SRC


** GF
*** Import 
#+BEGIN_SRC bash
g.mapset -c GF

r.external source=${DATADIR}/Karlsson_2021/GF.tif output=GF_ann
g.region raster=GF_ann
g.region res=1000 -pa
r.mapcalc "GF = GF_ann / 365"
#+END_SRC
*** Apply

#+BEGIN_SRC bash
r.univar -t --q map=GF zones=sectors_e@Zwally_2012 \
  | cut -d"|" -f1,13 \
  | datamash -t"|" transpose \
  | sed s/^sum/daily/ \
  > ./tmp/BMB_GF_sector.bsv

r.univar -t --q map=GF zones=basins_e@Mouginot_2019 \
  | cut -d"|" -f1,13 \
  | datamash -t"|" transpose \
  | sed s/^sum/daily/ \
  > ./tmp/BMB_GF_basin.bsv

r.univar -t --q map=GF zones=regions_e@Mouginot_2019 \
  | cut -d"|" -f1,13 \
  | datamash -t"|" transpose \
  | sed s/^sum/daily/ \
  > ./tmp/BMB_GF_region.bsv
#+END_SRC

** Velocity
*** Import
#+BEGIN_SRC bash
g.mapset -c vel

r.external source=${DATADIR}/Karlsson_2021/vel.tif output=vel_ann
g.region raster=vel_ann
g.region res=1000 -pa
r.mapcalc "vel = vel_ann / 365"
#+END_SRC

*** Apply

TODO: Convert vel from NBK units to...  m melt per grid cell?

#+BEGIN_SRC bash
r.univar -t --q map=vel zones=sectors_e@Zwally_2012 \
  | cut -d"|" -f1,13 \
  | datamash -t"|" transpose \
  | sed s/^sum/daily/ \
  > ./tmp/BMB_vel_sector.bsv

r.univar -t --q map=vel zones=basins_e@Mouginot_2019 \
  | cut -d"|" -f1,13 \
  | datamash -t"|" transpose \
  | sed s/^sum/daily/ \
  > ./tmp/BMB_vel_basin.bsv

r.univar -t --q map=vel zones=regions_e@Mouginot_2019 \
  | cut -d"|" -f1,13 \
  | datamash -t"|" transpose \
  | sed s/^sum/daily/ \
  > ./tmp/BMB_vel_region.bsv
#+END_SRC

** VHD
*** Setup
**** Source contribution map

+ Determine VHD routing map as per citet:mankoff_2017_VHD
+ For each source cell, estimate the contribution to that sector VHD per unit mass of water
  + That is, from the water source, the integrated VHD between source and outlet.
  + Rather than doing full routing for each and every interior cell, the integrated VHD per cell can be estimated as the difference between the source pressure+elevation and the basal pressure+elevation terms.
+ Then, use this source map applied to each day of runoff from one of the RCMs.

Do the initial work in BedMachine (3413), then re-project into MAR because that is the RCM with future data.

**** Import BedMachine v3
+ from [[textcite:Morlighem:2017BedMachine][Morlighem /et al./ (2017)]]

#+BEGIN_SRC bash :results verbatim
log_info "Importing BedMachine"

g.mapset -c VHD

for var in $(echo mask surface bed thickness); do
  echo $var
  r.external source=netCDF:${DATADIR}/Morlighem_2017/BedMachineGreenland-2017-09-20.nc:${var} output=${var}
done

g.region raster=surface
g.region save=BedMachine

r.colors map=mask color=haxby
r.mapcalc "mask_ice_0 = if(mask == 2, 1, null())"
#+END_SRC

**** Expand Mask

The ice mask needs to be expanded so that land terminating glaciers contain 1 grid cell outside the ice domain. This is so that the discharge location has 0 thickness (0 pressure term) and all pressure energy is released. Only gravitational potential energy remains. Submarine discharge remains pressurized by the ice thickness.

#+BEGIN_SRC bash
r.grow input=mask_ice_0 output=mask_ice_1 radius=1.5 new=1
r.mapcalc "mask_01 = if((mask == 0) | (mask == 3), null(), mask_ice_1)"
#+END_SRC

**** Fill in small holes

Also fills in nunatuks.

This is done because hydrologic routing will terminate at domain boundaries, even if they're inland. We want to route to the ice edge, because eventually that is where all the water goes.

#+BEGIN_SRC bash :results verbatim
r.colors map=mask color=haxby
r.mapcalc "not_ice = if(isnull(mask_01) ||| (mask != 2), 1, 0)"

# No mask, NULLS are not clumped
r.clump input=not_ice output=clumps
# d.rast clumps
main_clump=$(r.stats -c -n clumps sort=desc | head -n1 | cut -d" " -f1)
r.mask -i raster=clumps maskcats=${main_clump} --o

r.mapcalc "all_ice = 1"
r.clump input=all_ice output=clumps2
# d.rast clumps2
main_clump=$(r.stats -c -n clumps2 sort=desc | head -n1 | cut -d" " -f1)
r.mask raster=clumps2 maskcats=${main_clump} --o

r.mapcalc "mask_ice = MASK"
# ice mask with no islands

# # original mask ice
# r.mask -r
# r.mapcalc "mask_ice_islands = if(mask == 2, 1, null())"
#+END_SRC
#+RESULTS:


**** Hydropotential head

#+BEGIN_SRC bash :results verbatim
log_info "Calculating subglacial head with k = 1.0"
r.mapcalc "pressure = 1 * 0.917 * thickness"
r.mapcalc "head = mask_ice * bed + pressure"
#+END_SRC

***** Streams

After calculating the head, we use 3rd party tools to get the flow direction and streams

#+NAME: streams
#+BEGIN_SRC bash :results verbatim
THRESH=300
log_warn "Using threshold: ${THRESH}"
log_info "r.stream.extract..."

r.stream.extract elevation=head threshold=${THRESH} memory=16384 direction=dir stream_raster=streams stream_vector=streams
#+END_SRC

***** Outlets

+ The flow direction =dir= is negative where flow leaves the domain. These are the outlets.
+ Encode each outlet with a unique id

#+NAME: outlets
#+BEGIN_SRC bash :results verbatim
log_info "Calculating outlets"
r.mapcalc "outlets_1 = if(dir < 0, 1, null())"
r.out.xyz input=outlets_1 | \
    cat -n | \
    tr '\t' '|' | \
    cut -d"|" -f1-3 | \
    v.in.ascii input=- output=outlets_uniq separator=pipe \
        columns="x int, y int, cat int" x=2 y=3 cat=1
#+END_SRC

***** Basins

Using =r.stream.basins=, we can get basins for every outlet.

#+NAME: basins
#+BEGIN_SRC bash :results verbatim
log_info "r.stream.basins..."

r.stream.basins -m direction=dir points=outlets_uniq basins=basins_uniq memory=16384 --verbose
#+END_SRC

**** Change in head between each cell and its outlet

#+BEGIN_SRC bash
r.stream.distance -o stream_rast=outlets_1 direction=dir elevation=head method=downstream difference=delta_head
r.stream.distance -o stream_rast=outlets_1 direction=dir elevation=bed method=downstream difference=delta_z_head
r.stream.distance -o stream_rast=outlets_1 direction=dir elevation=pressure method=downstream difference=delta_p_head
#+END_SRC

The effective head change is the change in the elevation head and the change in the pressure head, minus the change in pressure head that is occupied with the effect of changing pressure on the changing phase transition temperature (PTT; citet:mankoff_2017_VHD).

The relationship between changing pressure and changing PTT is,

#+NAME: eq:PTT
\begin{equation}
PTT = C_T C_p \rho_w,
\end{equation}

with \(C_T\) the Clausius-Clapeyron slope (8.6E-8 K Pa-1), \(c_p\) the specific heat of water (4184 J K-1 kg-1), and \(\rho_w\) the density of water (1000 kg m-3).

#+BEGIN_SRC bash :tangle no :results verbatim
frink "(8.6E-8 K Pa^(-1)) * (4184 J K^(-1) kg^(-1)) * (1000 kg m^(-3))"
#+END_SRC

#+RESULTS:
: 0.359824

Meaning 0.36 of the pressure reduction energy release is "lost", warming the water to match the increased PTT, and 1-0.36 = 0.64 of the pressure reduction energy release can be used to melt basal ice.

From citet:mankoff_2017_VHD or citet:karlsson_2021:

#+BEGIN_SRC bash
# The effective change in head is...
r.mapcalc "dh = delta_z_head + 0.64 * delta_p_head"
# also "dh = delta_head - 0.36 * delta_p_head"

# Energy (J) is m*g*z
r.mapcalc 'q_z = (1000 * 9.8 * delta_z_head)'
r.mapcalc 'q_p = (1000 * 9.8 * 0.64 * delta_p_head)'
r.mapcalc 'q = (1000 * 9.8 * dh)'

# r.mapcalc "q = (1000 * 9.8 * delta_head) - 0.36 * (917 * 9.8 * delta_p_head)"
r.mapcalc "unit_melt = q / (335 * 1000)" # 335 kJ/kg ice
#+END_SRC

***** Debug

+ Mask ice should be 1 pixel wider on land and 0 pixels wider for marine terminating glaciers. This is so that for land-terminating glaciers, the pressure head drops to 0 (thickness is 0) at the outlet, but for marine terminating glaciers, the pressure head should remain at ice thickness.

+ Click around... record values at an marine terminating outlet, and then click upstream on or off the stream and check that delta_z_head and delta_p_head make sense. Repeat for land-terminating outlet.  

#+BEGIN_SRC bash :tangle no
g.mapset -c tmp

r.to.vect input=mask output=mask type=area
r.to.vect input=mask_ice output=mask_ice type=area
r.to.vect input=basins_uniq output=basins type=area

d.mon wx0
d.erase

d.rast surface
d.rast bed
d.rast thickness
d.rast pressure
d.rast dir
d.rast delta_head
d.rast delta_p_head
d.rast delta_z_head

d.vect basins fill_color=none color=grey width=3
d.vect mask fill_color=none color=black width=3
d.vect mask_ice fill_color=none color=red
d.vect streams
d.vect outlets_uniq color=cyan
#+END_SRC

*** Apply
:PROPERTIES:
:header-args:bash+: :tangle BMB_MAR.sh
:END:

#+BEGIN_SRC bash
<<init_bash>>
<<init_grass>>
#+END_SRC

**** Reproject BedMachine derived change in pressure to MAR projection

#+BEGIN_SRC bash
g.mapset -c VHD
r.proj -pg location=G_BMB mapset=VHD input=unit_melt
eval $(r.proj -pg location=G_BMB mapset=VHD input=unit_melt)
g.region e=$e w=$w n=$n s=$s rows=$rows cols=$cols -p
g.region save=BedMachine
r.proj location=G_BMB mapset=VHD input=unit_melt output=unit_melt_res
g.region res=1000 -pa
r.mapcalc "unit_melt = unit_melt_res" # resample to regular grid
#+END_SRC

**** MAR daily partitioned to ROI

#+BEGIN_SRC bash :results verbatim

RCM=MAR
mkdir -p tmp/BMB

dir=${DATADIR}/${RCM}/daily
f=$(ls ${dir}/MARv3.11*.nc|head -n1) # debug

for f in ${dir}/MARv3.11*.nc; do
  dates=$(python ./nc_dates.py ${f})
  band=0
  d=1986-01-01 # debug
  for d in ${dates}; do
    band=$(( ${band} + 1 ))

    log_info "MAR BMB: ${d}"

    if [[ -e ./tmp/BMB/sector_${d}.bsv ]]; then continue; fi

    r.in.gdal -o input="NetCDF:${f}:RU" band=${band} output=ru_raw --o --q
    r.region map=ru_raw region=RCM

    # ru_raw in mm w eq runoff
    # Other BMB is m/day equivalent melt, so we should aim for that.
    r.mapcalc "vhd = unit_melt * (10^-3.0) * if(mask > 50, ru_raw * (mask/100), null())" --o
    
    r.null map=vhd null=0

    r.univar -t --q map=vhd zones=sectors_e@Zwally_2012 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/BMB/sector_${d}.bsv

    r.univar -t --q map=vhd zones=basins_e@Mouginot_2019 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/BMB/basin_${d}.bsv

    r.univar -t --q map=vhd zones=regions_e@Mouginot_2019 \
    | cut -d"|" -f1,13 \
    | datamash -t"|" transpose \
    | sed s/^sum/${d}/ \
    > ./tmp/BMB/region_${d}.bsv
    
  done
done
#+END_SRC




** Create data file
*** Merge BSVs

#+BEGIN_SRC bash :tangle bmb_merge.sh :results verbatim
<<init_bash>>

for ROI in sector region basin; do
  log_info MAR ${ROI}
  head -n1 ./tmp/BMB/${ROI}_2000-01-01.bsv > ./tmp/BMB_VHD_${ROI}.bsv
  tail -q -n1 ./tmp/BMB/${ROI}_*.bsv >> ./tmp/BMB_VHD_${ROI}.bsv
done
#+END_SRC

#+RESULTS:
: 
: $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ > > > > [0;32m[2021-02-03T13:54:26-08:00] [INFO] MAR sector[0m
: [0;32m[2021-02-03T13:54:26-08:00] [INFO] MAR region[0m
: [0;32m[2021-02-03T13:54:26-08:00] [INFO] MAR basin[0m


*** BSV to NetCDF

# #+NAME: bmb_bsv2nc
#+BEGIN_SRC jupyter-python :tangle bmb_bsv2nc.py
import pandas as pd
import xarray as xr
import numpy as np
import datetime

time = pd.date_range(start = "1986-01-01",
                     end = datetime.date.today() + datetime.timedelta(days = 10),
                     freq = "D")

bmb = xr.Dataset()
bmb["time"] = (("time"), time)

bmb["sector"] = pd.read_csv("./tmp/BMB_GF_sector.bsv", delimiter="|", nrows=0, index_col=0).columns.astype(int)

rstr = {11:'NW', 12:'NO', 1:'NE', 3:'CE', 9:'CW', 5:'SE', 7:'SW'}
rnum = pd.read_csv("./tmp/BMB_GF_region.bsv", delimiter="|", nrows=0, index_col=0).columns.astype(int)
bmb["region"] = [rstr[n] for n in rnum]
bmb["basin"] = pd.read_csv("./tmp/BMB_GF_basin.bsv", delimiter="|", nrows=0, index_col=0).columns.astype(int)

bmb['GF_sector'] = (('sector'),
                    pd.read_csv("./tmp/BMB_GF_sector.bsv",
                                delimiter="|", index_col=0).values.flatten())
bmb['vel_sector'] = (('sector'),
                     pd.read_csv("./tmp/BMB_vel_sector.bsv",
                                 delimiter="|", index_col=0).values.flatten())
bmb['VHD_sector'] = (('time','sector'),
                     pd.read_csv("./tmp/BMB_VHD_sector.bsv",
                                 delimiter="|", index_col=0, parse_dates=True).reindex(time))

bmb['GF_region'] = (('region'),
                    pd.read_csv("./tmp/BMB_GF_region.bsv",
                                delimiter="|", index_col=0).values.flatten())
bmb['vel_region'] = (('region'),
                     pd.read_csv("./tmp/BMB_vel_region.bsv",
                                 delimiter="|", index_col=0).values.flatten())
bmb['VHD_region'] = (('time','region'),
                     pd.read_csv("./tmp/BMB_VHD_region.bsv",
                                 delimiter="|", index_col=0, parse_dates=True).reindex(time))

bmb['GF_basin'] = (('basin'),
                    pd.read_csv("./tmp/BMB_GF_basin.bsv",
                                delimiter="|", index_col=0).values.flatten())
bmb['vel_basin'] = (('basin'),
                     pd.read_csv("./tmp/BMB_vel_basin.bsv",
                                 delimiter="|", index_col=0).values.flatten())

df = pd.read_csv("./tmp/BMB_VHD_basin.bsv",
                 delimiter="|", index_col=0, parse_dates=True).reindex(time)
df.columns = df.columns.astype(np.int64)
missing = bmb['basin'].values[~pd.Series(bmb['basin'].values).isin(df.columns)]
if len(missing) > 0:
    df[missing] = np.nan
    df = df.reindex(sorted(df.columns), axis=1)
bmb['VHD_basin'] = (('time','basin'), df)


# VHD is in mm w.eq / day
# scale from my computed daily VHD to the same units NBK BMB is on, which is [m w.eq]
for roi in ['sector','region','basin']:
    v = 'VHD_'+roi
    bmb[v] = (('time',roi), bmb[v] * 1E-3)

#          grid cells    m^3->kg  kg->Gt
bmb = bmb * 1000 * 1000 * 1E3    / 1E12
bmb.to_netcdf("./tmp/bmb.nc")

print(bmb)
#+END_SRC

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:     (basin: 252, region: 7, sector: 19, time: 12830)
Coordinates:
  ,* time        (time) datetime64[ns] 1986-01-01 1986-01-02 ... 2021-02-15
  ,* sector      (sector) int64 11 12 13 14 21 22 31 32 ... 50 61 62 71 72 81 82
  ,* region      (region) <U2 'NE' 'CE' 'SE' 'SW' 'CW' 'NW' 'NO'
  ,* basin       (basin) int64 1 2 3 4 5 6 7 8 ... 252 253 254 255 257 258 259
Data variables:
    GF_sector   (sector) float64 0.000863 0.0002914 ... 0.001457 0.0001964
    vel_sector  (sector) float64 0.00149 0.0002846 ... 0.005806 0.0002424
    VHD_sector  (time, sector) float64 0.007683 0.001881 0.001076 ... nan nan
    GF_region   (region) float64 0.003862 0.001717 ... 0.001706 0.001373
    vel_region  (region) float64 0.003037 0.003699 ... 0.006114 0.001899
    VHD_region  (time, region) float64 0.008228 0.01525 1.626 ... nan nan nan
    GF_basin    (basin) float64 2.533e-05 3.625e-05 ... 5.112e-07 2.702e-06
    vel_basin   (basin) float64 3.52e-05 1.833e-05 ... 7.486e-11 1.901e-10
    VHD_basin   (time, basin) float64 -0.0001209 -7.146e-05 0.001836 ... nan nan
#+end_example


* TMB
Generate a TMB netcdf file from SMB, MMB, and BMB

** Load SMB

#+NAME: load_smb
#+BEGIN_SRC jupyter-python
<<py_import>>

smb = xr.open_dataset("./tmp/smb.nc")
smb['region'] = smb['region'].astype(str)
#+END_SRC

#+RESULTS: load_smb

** Load MMB (Mankoff 2020)

#+NAME: load_mmb
#+BEGIN_SRC jupyter-python
import xarray as xr

ds = xr.open_dataset("/home/kdm/data/Mankoff_2020/ice/latest/gate.nc")

# rstr = {'NW':11, 'NO':12, 'NE':1, 'CE':3, 'CW':9, 'SE':5, 'SW':7}
# rnum = [rstr[r] for r in ds['region'].values]
# ds['region'] = (('gate'), rnum)

ds_sector = ds.drop_vars(["mean_x","mean_y","mean_lon","mean_lat","sector","region","coverage"])\
          .groupby("Zwally_2012")\
          .sum()\
          .rename({"Zwally_2012":"sector",
                   "discharge":"mmb_sector",
                   "err":"err_sector"})

ds_region = ds.drop_vars(["mean_x","mean_y","mean_lon","mean_lat","sector","Zwally_2012","coverage"])\
          .groupby("region")\
          .sum()\
          .rename({"discharge":"mmb_region",
                   "err":"err_region"})


ds_basin = ds.drop_vars(["mean_x","mean_y","mean_lon","mean_lat","Zwally_2012","region","coverage"])\
          .groupby("sector")\
          .sum()\
          .rename({"sector":"basin",
                   "discharge":"mmb_basin",
                   "err":"err_basin"})

mmb = ds_sector
mmb = mmb.merge(ds_region)
mmb = mmb.merge(ds_basin)

mmb['mmb'] = (('time'), mmb['mmb_sector'].sum(dim='sector'))
mmb['mmb_err'] = (('time'), mmb['err_sector'].sum(dim='sector'))

# convert from Gt/year @ misc time-steps -> Gt/day @ daily timestep
msave = mmb.copy(deep=True)
mmb = (mmb / 365).resample({"time":"1D"})\
                 .mean()\
                 .interpolate_na(dim="time")

# I want monotonic cubic interpolation for discharge
mmb['mmb'] = (('time'), (msave['mmb']/365).resample({'time':'1D'}).mean().to_dataframe().interpolate(method='pchip').values.flatten())
mmb['region'] = mmb['region'].astype(str)
#+END_SRC

#+RESULTS: load_mmb


** Load BMB (Karlsson 202)

#+NAME: load_bmb
#+BEGIN_SRC jupyter-python
<<py_import>>

bmb = xr.open_dataset("./tmp/bmb.nc")
bmb['region'] = bmb['region'].astype(str)

bmb['bmb'] = bmb['VHD_sector'].sum(dim='sector') \
    + bmb['GF_sector'].sum(dim='sector') \
    + bmb['vel_sector'].sum(dim='sector')

print(bmb)
bmb[['VHD_sector','GF_sector','vel_sector','bmb']].sum(dim='sector').to_dataframe().head()
#+END_SRC

#+RESULTS: load_bmb
:RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:     (basin: 252, region: 7, sector: 19, time: 12829)
Coordinates:
  ,* time        (time) datetime64[ns] 1986-01-01 1986-01-01 ... 1986-01-01
  ,* sector      (sector) int64 11 12 13 14 21 22 31 32 ... 50 61 62 71 72 81 82
  ,* region      (region) <U2 'NE' 'CE' 'SE' 'SW' 'CW' 'NW' 'NO'
  ,* basin       (basin) int64 1 2 3 4 5 6 7 8 ... 252 253 254 255 257 258 259
Data variables:
    GF_sector   (sector) float64 0.0008637 0.0002919 ... 0.001458 0.0001964
    vel_sector  (sector) float64 0.001533 0.0003148 ... 0.005934 0.0002597
    VHD_sector  (time, sector) float64 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0
    GF_region   (region) float64 ...
    vel_region  (region) float64 ...
    VHD_region  (time, region) float64 ...
    GF_basin    (basin) float64 ...
    vel_basin   (basin) float64 ...
    VHD_basin   (time, basin) float64 ...
    bmb         (time) float64 0.04964 0.04964 0.04964 ... 0.04964 0.04964
#+end_example
| time                |   VHD_sector |   GF_sector |   vel_sector |       bmb |
|---------------------+--------------+-------------+--------------+-----------|
| 1986-01-01 00:00:00 |            0 |   0.0163605 |    0.0332779 | 0.0496384 |
| 1986-01-01 00:00:00 |            0 |   0.0163605 |    0.0332779 | 0.0496384 |
| 1986-01-01 00:00:00 |            0 |   0.0163605 |    0.0332779 | 0.0496384 |
| 1986-01-01 00:00:00 |            0 |   0.0163605 |    0.0332779 | 0.0496384 |
| 1986-01-01 00:00:00 |            0 |   0.0163605 |    0.0332779 | 0.0496384 |
:END:


** Create TMB output
:PROPERTIES:
:header-args:jupyter-python+: :tangle build_TMB_nc.py
:END:


#+BEGIN_SRC jupyter-python
# Populate smb dataset
<<load_smb>>

# Populate mmb dataset
<<load_mmb>>

# Populate bmb dataset
<<load_bmb>>

# match times
t0 = np.min([smb['time'].min().values,
             mmb['time'].min().values,
             np.datetime64(datetime.datetime(year=1986, month=1, day=1))])
t1 = np.max([smb['time'].max().values,
             mmb['time'].max().values,
             np.datetime64(datetime.date.today() + datetime.timedelta(days = 7))])
time = pd.date_range(start=t0, end=t1, freq="D")
smb = smb.reindex({'time':time})
mmb = mmb.reindex({'time':time})
bmb = bmb.reindex({'time':time})

# add the sectors from SMB to MMB (14 and 21(?) don't have any MMB)
mmb = mmb.reindex({'sector': smb['sector']})# .fillna(0)
mmb = mmb.reindex({'basin': smb['basin']})# .fillna(0)
mmb = mmb.reindex({'region': smb['region']})# .fillna(0)
mmb['region'] = mmb['region'].astype(str)
mmb = mmb.ffill(dim='time')
mmb = mmb.bfill(dim='time')
#+END_SRC

#+RESULTS:


#+BEGIN_SRC jupyter-python
import subprocess

for roi in ['sector', 'region']: # TODO: 'basin'
    mb = xr.Dataset()
    
    mb["time"] = (("time"), time)
    mb["time"].attrs["cf_role"] = "timeseries_id"
    mb["time"].attrs["standard_name"] = "time"
    mb["time"].attrs["axis"] = "T"

    mb[roi] = ((roi), mmb[roi])
    if roi == 'sector':
        mb[roi].attrs["long_name"] = "Zwally 2012 sectors"
    elif roi == 'region':
        mb[roi].attrs["long_name"] = "Mouginot 2019 regions"
    elif roi == 'basin':
        mb[roi].attrs["long_name"] = "Mouginot 2019 basins"
       

    mb['mb'] = (('time'), smb['smb'] - mmb['mmb'])

    v = 'mb'
    mb[v].attrs["long_name"] = "Mass balance"
    mb[v].attrs["standard_name"] = "land_ice_mass_tranport"
    mb[v].attrs["units"] = "Gt d-1"
    mb[v].attrs["coordinates"] = 'time'
    
    mb['mb_ROI'] = (('time',roi), smb['smb_'+roi] - mmb['mmb_'+roi])
    # mb['mb_ROI'].attrs = mb['mb'].attrs
    # mb['mb_ROI'].attrs["coordinates"] = 'time ROI'

    # if roi == 'region':
    #     from IPython import embed; embed()
    
    mb['smb'] = (('time'), smb['smb'])
    mb['smb_ROI'] = (('time',roi), smb['smb_'+roi])
    # mb['smb_HIRHAM'] = (('time',roi), smb['HIRHAM_'+roi]-mmb['mmb_'+roi] )
    # mb['smb_MAR'] = (('time',roi), smb['HIRHAM_'+roi]-mmb['mmb_'+roi])
    # mb['smb_RACMO'] = (('time',roi), smb['HIRHAM_'+roi]-mmb['mmb_'+roi])
    for v in ['smb', 'smb_ROI']:
        mb[v].attrs['long_name'] = 'Surface mass balance'
        mb[v].attrs["standard_name"] = "land_ice_mass_tranport"
        mb[v].attrs["units"] = "Gt d-1"
        mb[v].attrs["coordinates"] = 'time ROI'

       
    mb['mmb'] = (('time'), mmb['mmb'])
    mb['mmb_ROI'] = (('time',roi), mmb['mmb_'+roi])
    for v in ['mmb','mmb_ROI']:
        mb[v].attrs['long_name'] = 'Marine mass balance'
        mb[v].attrs["standard_name"] = "land_ice_mass_tranport"
        mb[v].attrs["units"] = "Gt d-1"
    mb['mmb'].attrs["coordinates"] = 'time'
    mb['mmb_ROI'].attrs["coordinates"] = 'time ROI'

    
    mb['bmb'] = (('time'), bmb['bmb'])
    mb['bmb_ROI'] = (('time',roi), bmb['bmb_'+roi])
    for v in ['bmb','bmb_ROI']:
        mb[v].attrs['long_name'] = 'Marine mass balance'
        mb[v].attrs["standard_name"] = "land_ice_mass_tranport"
        mb[v].attrs["units"] = "Gt d-1"
    mb['bmb'].attrs["coordinates"] = 'time'
    mb['bmb_ROI'].attrs["coordinates"] = 'time ROI'
    
        
    # mb['bmb'] = (('time'), bmb['bmb'])
    # mb['bmb_ROI'] = (('time',roi), bmb['bmb_'+roi])
    # mb['bmb_GF_ROI'] = (('time',roi), bmb['bmb_GF_'+roi])
    # mb['bmb_vel_ROI'] = (('time',roi), bmb['bmb_vel_'+roi])
    # mb['bmb_VHD_ROI'] = (('time',roi), bmb['bmb_VHD_'+roi])
    # for v in ['bmb','bmb_ROI']:
    #     mb[v].attrs['long_name'] = 'Basal mass balance'
    #     mb[v].attrs["standard_name"] = "land_ice_mass_tranport"
    #     mb[v].attrs["units"] = "Gt d-1"
    # mb['bmb'].attrs["coordinates"] = 'time'
    # mb['bmb_ROI'].attrs["coordinates"] = 'time ROI'

    for RCM in ['HIRHAM','MAR','RACMO']:
        mb['mb_'+RCM] = (('time',roi), smb[RCM+'_'+roi]-mmb['mmb_'+roi] )
        v = 'mb_'+RCM
        mb[v].attrs['long_name'] = 'Mass balance from ' + v.split('_')[1]
        mb[v].attrs["standard_name"] = "land_ice_mass_tranport"
        mb[v].attrs["units"] = "Gt d-1"
        mb[v].attrs["coordinates"] = 'time ROI'
        
    # if roi == 'region':
    #     from IPython import embed; embed()
        # smb['smb_'+roi].sel({'region':'CE'}), '\n\n', mmb['mmb_'+roi].sel({'region':'CE'}), '\n\n', (smb['smb_'+roi] - mmb['mmb_'+roi]).sel({'region':'CE'}), '\n\n', mb.sel({'region':'CE'})
        # smb['smb_'+roi].isel({'time':0}), '\n\n', mmb['mmb_'+roi].isel({'time':0}), '\n\n', (smb['smb_'+roi] - mmb['mmb_'+roi]).isel({'time':0}), '\n\n', mb.isel({'time':0})

    
    mb.attrs["featureType"] = "timeSeries"
    mb.attrs["title"] = "Greenland mass balance"
    mb.attrs["summary"] = "Greenland mass balance"
    mb.attrs["keywords"] = "Greenland; Mass; Mass balance"
    # mb.attrs["Conventions"] = "CF-1.8"
    mb.attrs["source"] = "git commit: " + subprocess.check_output(["git", "describe", "--always"]).strip().decode('UTF-8')
    # mb.attrs["comment"] = "TODO"
    # mb.attrs["acknowledgment"] = "TODO"
    # mb.attrs["license"] = "TODO"
    # mb.attrs["date_created"] = datetime.datetime.now().strftime("%Y-%m-%d")
    mb.attrs["creator_name"] = "Ken Mankoff"
    mb.attrs["creator_email"] = "kdm@geus.dk"
    mb.attrs["creator_url"] = "http://kenmankoff.com"
    mb.attrs["institution"] = "GEUS"
    # mb.attrs["time_coverage_start"] = "TODO"
    # mb.attrs["time_coverage_end"] = "TODO"
    # mb.attrs["time_coverage_resolution"] = "TODO"
    mb.attrs["references"] = "10.22008/promice/mass_balance"
    mb.attrs["product_version"] = 1.0

    comp = dict(zlib=True, complevel=2)
    encoding = {var: comp for var in mb.data_vars} # all

    mb.to_netcdf('./TMB/mb_'+roi+'.nc', mode='w', encoding=encoding)
#+END_SRC

#+RESULTS:



* Validation prep
** IO (Mouginot)

#+name: load_mouginot
#+BEGIN_SRC jupyter-python

ds = xr.Dataset()

df = pd.read_excel('/home/kdm/data/Mouginot_2019/pnas.1904242116.sd02.xlsx', sheet_name=1)

## Discharge
c0 = 15 # Column containing 1972
c1 = 61 # Last column
r0 = 8 # sub-table start [LibreOffice is 1-based, Python is 0-based]
r1 = 15 # sub-table stop

ds['time'] = (('time'), pd.to_datetime(df.iloc[r0-1][df.columns[c0:(c1 + 1)]].astype(np.int).values, format="%Y"))
ds['region'] = (('region'), df.iloc[r0:r1][df.columns[1]])
ds['D'] = (('time','region'), df.iloc[r0:r1][df.columns[c0:(c1 + 1)]].values.T.astype(np.float))

c2  = 82; c3 = 128
ds['D_err'] = (('time','region'), df.iloc[r0:r1][df.columns[c2:(c3 + 1)]].values.T.astype(np.float))

r0 = 20; r1=27
ds['SMB'] = (('time','region'), df.iloc[r0:r1][df.columns[c0:(c1 + 1)]].values.T.astype(np.float))
ds['SMB_err'] = (('time','region'), df.iloc[r0:r1][df.columns[c2:(c3 + 1)]].values.T.astype(np.float))

r0 = 30; r1=37
ds['MB'] = (('time','region'), df.iloc[r0:r1][df.columns[c0:(c1 + 1)]].values.T.astype(np.float))
ds['MB_err'] = (('time','region'), df.iloc[r0:r1][df.columns[c2:(c3 + 1)]].values.T.astype(np.float))

mouginot = ds
# print(mouginot)
#+END_SRC

#+RESULTS: load_mouginot

** SEC

Not much to do because SEC from Simonsen (2021) provided as MB by ROI

#+BEGIN_SRC bash :results verbatim
ncdump -chs ${DATADIR}/Simonsen_2021/ds1.nc
#+END_SRC

#+RESULTS:
#+begin_example
netcdf ds1 {
dimensions:
	t = 28 ;
variables:
	float Start_time(t) ;
		Start_time:long_name = "Time of first observation" ;
		Start_time:standard_name = "Start_time" ;
		Start_time:units = "decimal year" ;
		Start_time:_Storage = "contiguous" ;
		Start_time:_Endianness = "little" ;
	float time(t) ;
		time:long_name = "Midpoint of SEC obs." ;
		time:standard_name = "time" ;
		time:units = "decimal year" ;
		time:_Storage = "contiguous" ;
		time:_Endianness = "little" ;
	float End_time(t) ;
		End_time:long_name = "Time of last observation" ;
		End_time:standard_name = "End_time" ;
		End_time:units = "decimal year" ;
		End_time:_Storage = "contiguous" ;
		End_time:_Endianness = "little" ;
	float VMB(t) ;
		VMB:long_name = "Rate of mass balance" ;
		VMB:units = "Gt/year" ;
		VMB:_Storage = "chunked" ;
		VMB:_ChunkSizes = 28 ;
		VMB:_DeflateLevel = 4 ;
		VMB:_Shuffle = "true" ;
		VMB:_Endianness = "little" ;
	float VMBer(t) ;
		VMBer:long_name = "Rate of mass balance uncertainty" ;
		VMBer:units = "Gt/year" ;
		VMBer:_Storage = "chunked" ;
		VMBer:_ChunkSizes = 28 ;
		VMBer:_DeflateLevel = 4 ;
		VMBer:_Shuffle = "true" ;
		VMBer:_Endianness = "little" ;
	float VMB_basin_1(t) ;
		VMB_basin_1:long_name = "Rate of mass balance of Zwally basin 1" ;
		VMB_basin_1:units = "Gt/year" ;
		VMB_basin_1:_Storage = "chunked" ;
		VMB_basin_1:_ChunkSizes = 28 ;
		VMB_basin_1:_DeflateLevel = 4 ;
		VMB_basin_1:_Shuffle = "true" ;
		VMB_basin_1:_Endianness = "little" ;
	float VMBer_basin_1(t) ;
		VMBer_basin_1:long_name = "Rate of mass balance uncertainty of Zwally basin 1" ;
		VMBer_basin_1:units = "Gt/year" ;
		VMBer_basin_1:_Storage = "chunked" ;
		VMBer_basin_1:_ChunkSizes = 28 ;
		VMBer_basin_1:_DeflateLevel = 4 ;
		VMBer_basin_1:_Shuffle = "true" ;
		VMBer_basin_1:_Endianness = "little" ;
	float VMB_basin_2(t) ;
		VMB_basin_2:long_name = "Rate of mass balance of Zwally basin 2" ;
		VMB_basin_2:units = "Gt/year" ;
		VMB_basin_2:_Storage = "chunked" ;
		VMB_basin_2:_ChunkSizes = 28 ;
		VMB_basin_2:_DeflateLevel = 4 ;
		VMB_basin_2:_Shuffle = "true" ;
		VMB_basin_2:_Endianness = "little" ;
	float VMBer_basin_2(t) ;
		VMBer_basin_2:long_name = "Rate of mass balance uncertainty of Zwally basin 2" ;
		VMBer_basin_2:units = "Gt/year" ;
		VMBer_basin_2:_Storage = "chunked" ;
		VMBer_basin_2:_ChunkSizes = 28 ;
		VMBer_basin_2:_DeflateLevel = 4 ;
		VMBer_basin_2:_Shuffle = "true" ;
		VMBer_basin_2:_Endianness = "little" ;
	float VMB_basin_3(t) ;
		VMB_basin_3:long_name = "Rate of mass balance of Zwally basin 3" ;
		VMB_basin_3:units = "Gt/year" ;
		VMB_basin_3:_Storage = "chunked" ;
		VMB_basin_3:_ChunkSizes = 28 ;
		VMB_basin_3:_DeflateLevel = 4 ;
		VMB_basin_3:_Shuffle = "true" ;
		VMB_basin_3:_Endianness = "little" ;
	float VMBer_basin_3(t) ;
		VMBer_basin_3:long_name = "Rate of mass balance uncertainty of Zwally basin 3" ;
		VMBer_basin_3:units = "Gt/year" ;
		VMBer_basin_3:_Storage = "chunked" ;
		VMBer_basin_3:_ChunkSizes = 28 ;
		VMBer_basin_3:_DeflateLevel = 4 ;
		VMBer_basin_3:_Shuffle = "true" ;
		VMBer_basin_3:_Endianness = "little" ;
	float VMB_basin_4(t) ;
		VMB_basin_4:long_name = "Rate of mass balance of Zwally basin 4" ;
		VMB_basin_4:units = "Gt/year" ;
		VMB_basin_4:_Storage = "chunked" ;
		VMB_basin_4:_ChunkSizes = 28 ;
		VMB_basin_4:_DeflateLevel = 4 ;
		VMB_basin_4:_Shuffle = "true" ;
		VMB_basin_4:_Endianness = "little" ;
	float VMBer_basin_4(t) ;
		VMBer_basin_4:long_name = "Rate of mass balance uncertainty of Zwally basin 4" ;
		VMBer_basin_4:units = "Gt/year" ;
		VMBer_basin_4:_Storage = "chunked" ;
		VMBer_basin_4:_ChunkSizes = 28 ;
		VMBer_basin_4:_DeflateLevel = 4 ;
		VMBer_basin_4:_Shuffle = "true" ;
		VMBer_basin_4:_Endianness = "little" ;
	float VMB_basin_5(t) ;
		VMB_basin_5:long_name = "Rate of mass balance of Zwally basin 5" ;
		VMB_basin_5:units = "Gt/year" ;
		VMB_basin_5:_Storage = "chunked" ;
		VMB_basin_5:_ChunkSizes = 28 ;
		VMB_basin_5:_DeflateLevel = 4 ;
		VMB_basin_5:_Shuffle = "true" ;
		VMB_basin_5:_Endianness = "little" ;
	float VMBer_basin_5(t) ;
		VMBer_basin_5:long_name = "Rate of mass balance uncertainty of Zwally basin 5" ;
		VMBer_basin_5:units = "Gt/year" ;
		VMBer_basin_5:_Storage = "chunked" ;
		VMBer_basin_5:_ChunkSizes = 28 ;
		VMBer_basin_5:_DeflateLevel = 4 ;
		VMBer_basin_5:_Shuffle = "true" ;
		VMBer_basin_5:_Endianness = "little" ;
	float VMB_basin_6(t) ;
		VMB_basin_6:long_name = "Rate of mass balance of Zwally basin 6" ;
		VMB_basin_6:units = "Gt/year" ;
		VMB_basin_6:_Storage = "chunked" ;
		VMB_basin_6:_ChunkSizes = 28 ;
		VMB_basin_6:_DeflateLevel = 4 ;
		VMB_basin_6:_Shuffle = "true" ;
		VMB_basin_6:_Endianness = "little" ;
	float VMBer_basin_6(t) ;
		VMBer_basin_6:long_name = "Rate of mass balance uncertainty of Zwally basin 6" ;
		VMBer_basin_6:units = "Gt/year" ;
		VMBer_basin_6:_Storage = "chunked" ;
		VMBer_basin_6:_ChunkSizes = 28 ;
		VMBer_basin_6:_DeflateLevel = 4 ;
		VMBer_basin_6:_Shuffle = "true" ;
		VMBer_basin_6:_Endianness = "little" ;
	float VMB_basin_7(t) ;
		VMB_basin_7:long_name = "Rate of mass balance of Zwally basin 7" ;
		VMB_basin_7:units = "Gt/year" ;
		VMB_basin_7:_Storage = "chunked" ;
		VMB_basin_7:_ChunkSizes = 28 ;
		VMB_basin_7:_DeflateLevel = 4 ;
		VMB_basin_7:_Shuffle = "true" ;
		VMB_basin_7:_Endianness = "little" ;
	float VMBer_basin_7(t) ;
		VMBer_basin_7:long_name = "Rate of mass balance uncertainty of Zwally basin 7" ;
		VMBer_basin_7:units = "Gt/year" ;
		VMBer_basin_7:_Storage = "chunked" ;
		VMBer_basin_7:_ChunkSizes = 28 ;
		VMBer_basin_7:_DeflateLevel = 4 ;
		VMBer_basin_7:_Shuffle = "true" ;
		VMBer_basin_7:_Endianness = "little" ;
	float VMB_basin_8(t) ;
		VMB_basin_8:long_name = "Rate of mass balance of Zwally basin 8" ;
		VMB_basin_8:units = "Gt/year" ;
		VMB_basin_8:_Storage = "chunked" ;
		VMB_basin_8:_ChunkSizes = 28 ;
		VMB_basin_8:_DeflateLevel = 4 ;
		VMB_basin_8:_Shuffle = "true" ;
		VMB_basin_8:_Endianness = "little" ;
	float VMBer_basin_8(t) ;
		VMBer_basin_8:long_name = "Rate of mass balance uncertainty of Zwally basin 8" ;
		VMBer_basin_8:units = "Gt/year" ;
		VMBer_basin_8:_Storage = "chunked" ;
		VMBer_basin_8:_ChunkSizes = 28 ;
		VMBer_basin_8:_DeflateLevel = 4 ;
		VMBer_basin_8:_Shuffle = "true" ;
		VMBer_basin_8:_Endianness = "little" ;

// global attributes:
		:Title = "Radar mass balance of the Greenland Ice Sheet" ;
		:institution = "DTU Space - Div. of Geodesy and Earth Observation" ;
		:reference = "Simonsen et al. (2020)" ;
		:contact = "ssim@space.dtu.dk" ;
		:file_creation_date = "2020-09-14" ;
		:region = "Greenland" ;
		:missions_used = "ESA Radar altimeters: ERS-1, ERS-2, Envisat, CryoSat-2 and Sentinel-3" ;
		:time_coverage_start = "1992.0382513661202" ;
		:time_coverage_end = "2019.5341324200913" ;
		:Tracking_id = "47b09966-297e-4eb8-a621-f0c1337ab394" ;
		:netCDF_version = "NETCDF4" ;
		:product_version = "1.0" ;
		:Conventions = "CF-1.7" ;
		:summary = "Annual Mass balance for Greenland ice sheet and major drainage basins." ;
		:_NCProperties = "version=1|netcdflibversion=4.6.1|hdf5libversion=1.10.2" ;
		:_SuperblockVersion = 0 ;
		:_IsNetcdf4 = 1 ;
		:_Format = "netCDF-4" ;
}
#+end_example

*** Load SEC

#+NAME: load_sec
#+BEGIN_SRC jupyter-python
import xarray as xr
ds = xr.open_dataset("/home/kdm/data/Simonsen_2021/ds1.nc")
# print(ds)

sec = xr.Dataset()

t = pd.to_datetime([pd.to_datetime(str(int(np.floor(t)))+'-01-01') + pd.to_timedelta((t-np.floor(t))*365, unit='D') for t in ds.time.values])
sec['time'] = (("time"), t)

sec['sector'] = (("sector"), np.arange(1,9))

sec['SEC'] = (("time","sector"), ds[['VMB_basin_1','VMB_basin_2','VMB_basin_3','VMB_basin_4','VMB_basin_5','VMB_basin_6','VMB_basin_7','VMB_basin_8']].to_dataframe().values)
sec['err'] = (("time","sector"), ds[['VMBer_basin_1','VMBer_basin_2','VMBer_basin_3','VMBer_basin_4','VMBer_basin_5','VMBer_basin_6','VMBer_basin_7','VMBer_basin_8']].to_dataframe().values)
#+END_SRC

#+RESULTS:


** GRACE
:PROPERTIES:
:header-args:bash+: :tangle GRACE.sh
:END:

Set up the GRACE ROI

#+BEGIN_SRC bash
# grass ./G/GRACE
g.mapset -c GRACE

<<init_bash>>
<<init_grass>>

g.region region=sectors -p
g.region -d -p
g.region region=sectors -p
v.in.region output=roi

#+END_SRC

Import GRACE into its own location, ~grass -c EPSG:4326 G_GRACE~, and then crop to the current ROI

#+BEGIN_SRC bash :tangle GRACE_import.sh
g.region e=360 w=0 s=-90 n=90 res=0:30 -pa

parallel --bar "r.in.gdal -o input=NetCDF:${DATADIR}/GRACE/GRCTellus.JPL.200204_202009.GLO.RL06M.MSCNv02CRI.nc:lwe_thickness output=lwe_{1} band={#}" ::: $(python nc_dates.py ~/data/GRACE/GRCTellus.JPL.200204_202009.GLO.RL06M.MSCNv02CRI.nc)

parallel --bar "r.in.gdal -o input=NetCDF:${DATADIR}/GRACE/GRCTellus.JPL.200204_202009.GLO.RL06M.MSCNv02CRI.nc:uncertainty output=err_{1} band={#}" ::: $(python nc_dates.py ~/data/GRACE/GRCTellus.JPL.200204_202009.GLO.RL06M.MSCNv02CRI.nc)

# use the target ROI to crop in this ROI
v.proj location=G mapset=GRACE input=roi

g.region vector=roi -p align=lwe_2020_09_16
parallel --bar "r.mapcalc \"lwe_{1}_GL = lwe_{1}\"" ::: $(python nc_dates.py ~/data/GRACE/GRCTellus.JPL.200204_202009.GLO.RL06M.MSCNv02CRI.nc)
parallel --bar "r.mapcalc \"err_{1}_GL = err_{1}\"" ::: $(python nc_dates.py ~/data/GRACE/GRCTellus.JPL.200204_202009.GLO.RL06M.MSCNv02CRI.nc)
#+END_SRC

Execute the above

#+BEGIN_SRC bash
## load GRACE data in EPSG:4326 location
rm -fR G_GRACE
grass -c EPSG:4326 ./G_GRACE --exec ./GRACE_import.sh
#+END_SRC

Reproject GRACE into this location

#+BEGIN_SRC bash
parallel --bar "r.proj location=G_GRACE mapset=PERMANENT input=lwe_{1}_GL output=lwe_{1}" ::: $(python nc_dates.py ~/data/GRACE/GRCTellus.JPL.200204_202009.GLO.RL06M.MSCNv02CRI.nc)

parallel --bar "r.proj location=G_GRACE mapset=PERMANENT input=err_{1}_GL output=err_{1}" ::: $(python nc_dates.py ~/data/GRACE/GRCTellus.JPL.200204_202009.GLO.RL06M.MSCNv02CRI.nc)
#+END_SRC

Export GRACE

#+BEGIN_SRC bash
GRACE=$(g.list type=raster pattern=lwe_????_??_?? separator=comma)
GRACE_err=$(g.list type=raster pattern=err_????_??_?? separator=comma)
LIST=sectors_e@Zwally_2012,regions_e@Mouginot_2019,basins_e@Mouginot_2019,${GRACE},${GRACE_err}

g.region res=10000
(echo ${LIST}; r.out.xyz input=${LIST} separator=comma | cut -d, -f3-) > ./tmp/GRACE_GRACE_err.csv
#+END_SRC

*** Display

#+NAME: load_grace
#+BEGIN_SRC jupyter-python
import pandas as pd
import xarray as xr

df = pd.read_csv("./tmp/GRACE_GRACE_err.csv")

# get dates
c_lwe = df.columns[['lwe_' in _ for _ in df.columns]]
c_err = df.columns[['err_' in _ for _ in df.columns]]
time = pd.to_datetime([_[4:] for _ in c_lwe], format="%Y_%m_%d")

# Convert from cm w.e./grid cell to Gt
df[c_lwe] = df[c_lwe] * 10000 * 10000 * 10 * 1E-12
df[c_err] = df[c_err] * 10000 * 10000 * 10 * 1E-12

gmb = xr.Dataset()
gmb['time'] = (("time"), time)
gmb['cell'] = (("cell"), np.arange(df.index.size))

gmb['GMB_sector'] = (("time","cell"), df[c_lwe].T.values)
gmb['GMB_region'] = (("time","cell"), df[c_lwe].T.values)
gmb['GMB_basin'] = (("time","cell"), df[c_lwe].T.values)

gmb['err_sector'] = (("time","cell"), df[c_err].T.values)
gmb['err_region'] = (("time","cell"), df[c_err].T.values)
gmb['err_basin'] = (("time","cell"), df[c_err].T.values)

gmb['sector'] = (('cell'), df['sectors_e@Zwally_2012'])
gmb['region'] = (('cell'), df['regions_e@Mouginot_2019'])
gmb['basin'] = (('cell'), df['basins_e@Mouginot_2019'])

# gmb['GMB_sector'].sum(dim='cell').to_dataframe().plot()
# gmb['GMB_sector'].sum(dim='cell').to_dataframe().head()
#+END_SRC

#+RESULTS: load_grace

** IMBIE

This spreadsheet contains the IMBIE-2019 datasets for Greenland, which includes data on the annual rate of change and cumulative change in Greenland’s ice sheet mass, its surface mass balance and ice discharge anomalies, and their estimated uncertainty. The data are expressed in units of rate of mass change (Gigatons per year – sheet 1, columns B, C, F, G, J and K) mass (Gigatons – sheet 1, columns D, E, H, I, L and M) and in units of equivalent mean global sea level rise (millimetres per year – sheet 2, columns B, C, F, G, J and K, and millimetres – sheet 2, columns D, E, H, I, L and M).

#+NAME: load_imbie
#+BEGIN_SRC jupyter-python
import pandas as pd
imbie = pd.read_excel("/home/kdm/data/IMBIE/imbie_dataset_greenland_dynamics-2020_02_28.xlsx", sheet_name=0, index_col=0, usecols=(0,1,2,3,4,5,6,9,10))\
       .rename(columns={"Rate of ice sheet mass change (Gt/yr)":"mb",
                        "Rate of ice sheet mass change uncertainty (Gt/yr)":"mb_err",
                        "Cumulative ice sheet mass change (Gt)" : "mb_cum",
	                "Cumulative ice sheet mass change uncertainty (Gt)" : "mb_cum_err",
                        "Rate of mass balance anomaly (Gt/yr)":"smb",
                        "Rate of mass balance anomaly uncertainty (Gt/yr)":"smb_err",
                        "Rate of ice dynamics anomaly (Gt/yr)":"D",
                        "Rate of ice dyanamics anomaly uncertainty (Gt/yr)":"D_err"})

imbie['index'] = pd.to_datetime('1980-01-01') + pd.to_timedelta((imbie.index-1980) * 365, unit="D")
# Appears that these fractional dates are supposed to be start-of-month? I think so...
# Let's hard-code this.
imbie['index'] = [pd.to_datetime(y + '-' + m + '-01') for y in imbie.index.astype(np.int).unique().astype(np.str) for m in np.arange(1,13).astype(np.str)]
imbie.index = imbie['index']
imbie = imbie.drop('index', axis='columns')
# imbie.tail(30)
#+END_SRC

#+RESULTS: load_imbie

** PROMICE MB

#+NAME: load_PROMICE_MB
#+BEGIN_SRC jupyter-python
def load_Colgan_2019(sheet=0):
    df_all = pd.read_excel("/home/kdm/data/Colgan_2019/MassBalance_07022019.xlsx", index_col=0, sheet_name=sheet)
    
    df_all = df_all.loc[df_all.index.dropna()].drop(index="Total")
    df_all.index = (df_all.index.astype(float) * 10).astype(int)
    df_all = df_all.T
    df_all = df_all.astype(float32)

    df = df_all.iloc[::2]
    df.index = pd.to_datetime(df.index, format="%Y")

    df_err = df_all.iloc[1::2]
    df_err.index = df.index
    return df, df_err

p,e = load_Colgan_2019(sheet=3)

promice = xr.Dataset()
promice['time'] = (("time"), p.index)
promice['sector'] = (("sector"), p.columns)
promice['D'] = (("time","sector"), p.values)
promice['D_err'] = (("time","sector"), p.values)

p,e = load_Colgan_2019(sheet=4)
promice['SMB'] = (("time","sector"), p.values)
promice['SMB_err'] = (("time","sector"), p.values)

p,e = load_Colgan_2019(sheet=5)
promice['MB'] = (("time","sector"), p.values)
promice['MB_err'] = (("time","sector"), p.values)

# print(promice)
#+END_SRC


* Figures
** Notes


%% ONE-COLUMN FIGURES

%%f
%\begin{figure}[t]
%\includegraphics[width=8.3cm]{FILE NAME}
%\caption{TEXT}
%\end{figure}
%
%%% TWO-COLUMN FIGURES
%
%%f
%\begin{figure*}[t]
%\includegraphics[width=12cm]{FILE NAME}
%\caption{TEXT}
%\end{figure*}


** DONE ROIs w/o coast

+ Coast is noisy and poorly defined due to different RCM boundaries
+ Generate ROIs without the coast, just interior divisions

#+BEGIN_SRC bash
grass -c ./G_RACMO/ROI
g.region region=sectors -pa

r.mask -r

g.copy vector=sectors_e@Zwally_2012,sector
g.copy vector=regions_e@Mouginot_2019,region

for roi in sector region; do
  v.to.lines input=${roi} output=${roi}_lines
  v.to.rast input=${roi}_lines output=${roi}_lines type=line use=val val=1

  r.grow input=mask_ice radius=-3 output=mask_ice_shrink
  r.mask mask_ice_shrink

  r.thin input=${roi}_lines output=${roi}_thin

  r.to.vect input=${roi}_thin output=${roi}_interior type=line

  v.clean input=${roi}_interior output=${roi}_clean tool=rmdangle threshold=10000

  v.generalize input=${roi}_clean output=${roi}_interior_general method=douglas threshold=5000
  v.generalize input=${roi}_interior_general output=${roi}_interior_smooth method=chaiken threshold=1

  v.out.ogr input=${roi}_interior_smooth output=./tmp/${roi}_interior.gpkg
done
#+END_SRC


** DONE SMB/MMB/MB timeseries
*** GIS
#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
from adjust_spines import adjust_spines as adj

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

# n = 4
# color = plt.cm.viridis(np.linspace(0.1,0.9,n)) # This returns RGBA; convert:
# hexcolor = map(lambda rgb:'#%02x%02x%02x' % (np.int(rgb[0]*255),np.int(rgb[1]*255),np.int(rgb[2]*255)),
#                tuple(color[:,0:-1]))
# mpl.rcParams['axes.prop_cycle'] = cycler('color' , hexcolor)

# plt.close(1)
fig = plt.figure(1, figsize=(8,6)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
ax = fig.add_subplot(211)

# MB (this)
mb = xr.open_dataset("./TMB/mb_sector.nc")
# mb['mb'] = (('time'), mb[['HIRHAM_sector','MAR_sector','RACMO_sector']].sum(dim='sector'))
# https://stackoverflow.com/questions/60944525/calculate-mean-of-several-xarray-variables
# mb['mb'] = mb[['HIRHAM_sector','MAR_sector','RACMO_sector']].sum(dim='sector').to_array(dim='new').mean('new')
# mb['mb'].to_dataframe(name='M2021').resample('AS').sum().plot(ax=ax, drawstyle='steps')

kw = {'ax':ax, 'legend':False, 'drawstyle':'steps-post'}

mb['smb'].to_dataframe(name='M2021')\
         .rename(columns={'M2021':'SMB'})\
         .resample('AS')\
         .sum()\
         .plot(color='b', linestyle=':', **kw)

(-1*mb['mmb']).to_dataframe(name='M2021')\
              .rename(columns={'M2021':'MMB'})\
              .resample('AS')\
              .sum()\
              .plot(color='gray', linestyle='--', **kw)

# axr = ax.twinx()
# mb['mmb'].to_dataframe(name='M2021')\
#          .rename(columns={'M2021':'MMB'})\
#          .resample('AS')\
#          .sum()\
#          .plot(ax=axr, legend=False, drawstyle='steps-post', color='gray', linestyle='--')
# axr.set_ylim([420,520])
mb_ann = mb['mb'].to_dataframe(name='M2021')\
                 .rename(columns={'M2021':'MB'})\
                 .resample('AS')\
                 .sum()
mb_ann.plot(color='k', linestyle='-', **kw)

mb_ann_pos = mb_ann.where(mb_ann['MB'] > 0, 0)
mb_ann_neg = mb_ann.where(mb_ann['MB'] < 0, 0)
ax.fill_between(mb_ann_pos.index, mb_ann_pos.values.flatten(), color='r', alpha=0.1, step='post')
ax.fill_between(mb_ann_neg.index, mb_ann_neg.values.flatten(), color='b', alpha=0.1, step='post')

plt.legend(loc='lower left')

ax2 = fig.add_subplot(212)

mb = mb.sel({'time':slice('2019-01-01','2019-12-31')})
mb['smb'].to_dataframe(name='M2021')\
         .rename(columns={'M2021':'SMB'})\
         .plot(ax=ax2, color='b', linestyle=':', legend=False, drawstyle='steps-post')

(-1*mb['mmb']).to_dataframe(name='M2021')\
              .rename(columns={'M2021':'MMB'})\
              .plot(ax=ax2, color='gray', linestyle='--', legend=False, drawstyle='steps-post')

axr = ax2.twinx()
(-1*mb['mmb']).to_dataframe(name='M2021')\
              .rename(columns={'M2021':'MMB'})\
              .plot(ax=axr, legend=False, color='gray', linestyle='--')

mb = mb['mb'].to_dataframe(name='M2021')\
             .rename(columns={'M2021':'MB'})

mb.plot(ax=ax2, color='k', linestyle='-', legend=False, drawstyle='steps-post')

mb_pos = mb.where(mb['MB'] > 0, 0)
mb_neg = mb.where(mb['MB'] < 0, 0)
ax2.fill_between(mb_pos.index, mb_pos.values.flatten(), color='r', alpha=0.1, step='post')
ax2.fill_between(mb_neg.index, mb_neg.values.flatten(), color='b', alpha=0.1, step='post')

ax.set_ylabel("Mass gain [Gt yr$^{-1}$]")
ax.set_xlabel("")
ax2.set_xlabel("Time [Year]")
ax2.set_ylabel("Mass gain [Gt d$^{-1}$]")
axr.set_ylabel("MMB loss [Gt d$^{-1}$]")
axr.set_yticklabels(np.round(np.abs(axr.get_yticks()),2))

adj(ax, ['left','bottom'])
adj(ax2, ['left','bottom'])
adj(axr, ['right','bottom'])
# plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)

plt.savefig('tmp/mb_ts.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:
: <ipython-input-92-87a12fc3241b>:100: UserWarning: FixedFormatter should only be used together with FixedLocator
:   axr.set_yticklabels(np.round(np.abs(axr.get_yticks()),2))

*** Sector

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
from adjust_spines import adjust_spines as adj

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=10)
rc('text', usetex=False)

plt.close()
fig = plt.figure(1, figsize=(2.5,1.5)) # w,h

mb = xr.open_dataset("./TMB/mb_region.nc")


for r in mb['region'].values:

    fig.clf()
    fig.set_tight_layout(True)
    ax = fig.add_subplot(111)
    kw = {'ax':ax, 'legend':False, 'drawstyle':'steps-post'}

    mb_r = mb.sel({'region':r})

    mb_r_smb = mb_r['smb_ROI'].to_dataframe(name='M2021')\
                              .resample('AS')\
                              .sum()\
                              .rename(columns={'M2021':'SMB'})
    mb_r_smb.plot(color='b', linestyle=':', **kw)
    # ax.fill_between(mb_r_smb.index,
    #                 mb_r_smb.values.flatten(),
    #                 color='b', alpha=0.25, step='post')
    
    (-1*mb_r['mmb_ROI']).to_dataframe(name='M2021')\
                        .resample('AS')\
                        .sum()\
                        .rename(columns={'M2021':'MMB'})\
                        .plot(color='gray', linestyle='--', **kw)

    mb_r_mb = mb_r['mb_ROI'].to_dataframe(name='M2021')\
                            .resample('AS')\
                            .sum()\
                            .rename(columns={'M2021':'MB'})
    mb_r_mb.plot(color='k', linestyle='-', **kw)

    mb_r_pos = mb_r_mb.where(mb_r_mb['MB'] > 0, 0)
    mb_r_neg = mb_r_mb.where(mb_r_mb['MB'] < 0, 0)
    ax.fill_between(mb_r_pos.index, mb_r_pos.values.flatten(), color='r', alpha=0.1, step='post')
    ax.fill_between(mb_r_neg.index, mb_r_neg.values.flatten(), color='b', alpha=0.1, step='post')
    # ax.fill_between(mb_r_mb.index,
    #                 mb_r_mb.values.flatten(),
    #                 color='k',
    #                 alpha=0.25,
    #                 step='post')


    # plt.legend(loc='lower left')

    # ax.set_ylabel("Mass gain [Gt yr$^{-1}$]")
    ax.set_ylabel("")
    ax.set_xlabel("")
    # yl = np.max(np.abs(ax.get_yticks()))
    # ax.set_yticks([yl,-yl])
    ax.set_xticks(ax.get_xlim())
    # ax.set_xticklabels(ax.get_xlim())

    adj(ax, ['left','bottom'])
    # plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)
    # plt.ion()
    # plt.show()
    plt.savefig('fig/mb_ts_'+r+'.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:


** DONE SMB/MMB/MB vs. all others time series

#+BEGIN_SRC jupyter-python :tangle fig_compare.py
import xarray as xr
import numpy as np
import pandas as pd

import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

# | Color       |   R |   G |   B | hex     |
# |-------------+-----+-----+-----+---------|
# | light blue  | 166 | 206 | 227 | #a6cee3 |
# | dark blue   |  31 | 120 | 180 | #1f78b4 |
# | light green | 178 | 223 | 138 | #b2df8a |
# | dark green  |  51 | 160 |  44 | #33a02c |
# | pink        | 251 | 154 | 153 | #fb9a99 |
# | red         | 227 |  26 |  28 | #e31a1c |
# | pale orange | 253 | 191 | 111 | #fdbf6f |
# | orange      | 255 | 127 |   0 | #ff7f00 |

C_M2021 = 'k'
C_M2019 = 'gray'
C_GMB = '#e31a1c'
C_SEC = '#045a8d' # '1f78b4'
# C_IMBIE = '#2b8cbe' # '#ff7f00'
C_IMBIE = '#74a9cf'
C_PROMICE = '#fdbf6f'

# plt.close(1)
fig = plt.figure(1, figsize=(8,6)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
ax = fig.add_subplot(111)

kw = {'clip_on':True, 'linewidth':1, 'legend':False}
kw_err = {'clip_on':True, 'linewidth':1, 'alpha':0.1}

# MB (this)
mb = xr.open_dataset("./TMB/mb_sector.nc")
M2021 = mb['mb'].to_dataframe(name='M2021').cumsum()
M2021 = M2021 - np.min(M2021)
M2021_err = (mb['mb']*0.25).to_dataframe('M2021')[::-1].cumsum()[::-1]
p_M2021 = M2021.plot(ax=ax, color=C_M2021, **kw)
ax.fill_between(M2021.index,
                (M2021 - M2021_err).values.flatten(),
                (M2021 + M2021_err).values.flatten(),
                color=C_M2021, **kw_err)


# # Mouginot
if 'mouginot' not in locals():
    <<load_mouginot>>
M2019 = mouginot['MB'].sum(dim='region').to_dataframe('M2019').cumsum()
M2019 = M2019 - np.min(M2019) + 600
M2019_err = mouginot['MB_err'].sum(dim='region').to_dataframe('M2019')[::-1].cumsum()[::-1]
M2019 = M2019[M2019.index.year >= 1986]
M2019_err = M2019_err[M2019_err.index.year >= 1986]
p_M2019 = M2019.plot(ax=ax, label='M2019', color=C_M2019, **kw)
(M2019-M2019_err).plot(ax=ax, color=C_M2019, alpha=0.25, **kw)
(M2019+M2019_err).plot(ax=ax, color=C_M2019, alpha=0.25, **kw)



# GRACE
<<load_grace>>
gmb_sum = gmb['GMB_sector'].sum(dim='cell').to_dataframe(name="GRACE")
gmb_sum = gmb_sum - np.min(gmb_sum)
gmb_err = gmb['err_sector'].sum(dim='cell').to_dataframe(name="GRACE")
p_gmb = gmb_sum.plot(ax=ax, label='GRACE', color=C_GMB, **kw)
ax.fill_between(gmb_err.index,
                (gmb_sum - gmb_err).values.flatten(),
                (gmb_sum + gmb_err).values.flatten(),
                color=C_GMB, **kw_err)



# SEC
<<load_sec>>
sec_sum = sec['SEC'].sum(dim='sector').to_dataframe(name='SEC').cumsum()
sec_sum = sec_sum - np.min(sec_sum) + 450
sec_err = sec['err'].sum(dim='sector').to_dataframe(name='SEC')[::-1].cumsum()[::-1]
p_SEC = sec_sum.plot(ax=ax, label='SEC', color=C_SEC, **kw)
(sec_sum - sec_err).plot(ax=ax, linestyle='--', color=C_SEC, **kw)
(sec_sum + sec_err).plot(ax=ax, linestyle='--', color=C_SEC, **kw)




# IMBIE
<<load_imbie>>
imbie = imbie[['mb_cum','mb_cum_err']].dropna()
imbie['mb_cum'] = imbie['mb_cum'] - np.min(imbie['mb_cum']) + 500
p_IMBIE = imbie['mb_cum'].plot(ax=ax, label='IMBIE', color=C_IMBIE, **kw)
ax.fill_between(imbie.index,
               imbie['mb_cum'] - imbie['mb_cum_err'][::-1].values,
               imbie['mb_cum'] + imbie['mb_cum_err'][::-1].values,
               color=C_IMBIE, **kw_err)



# PROMICE MB (Colgan 2019)
<<load_PROMICE_MB>>
P = promice['MB'].sum(dim="sector").to_dataframe('C2019').cumsum()
P = P - np.min(P) + 1000
P_err = promice['MB_err'].sum(dim="sector").to_dataframe('C2019')[::-1].cumsum()[::-1]
p_PROMICE = P.plot(ax=ax, label='C2019', color=C_PROMICE, **kw)
ax.fill_between(P.index.values, (P-P_err).values.flatten(), (P+P_err).values.flatten(), color = C_PROMICE, **kw_err)

from adjust_spines import adjust_spines as adj
adj(ax, ['right','bottom'])

ax.set_ylabel("Mass change [Gt]")
ax.set_xlabel("Time [Year]")
ax.set_ylim([0,7000])

color = [C_M2021, C_M2019, C_GMB, C_SEC, C_IMBIE, C_PROMICE]
label = ['M2021', 'M2019', 'GRACE', 'SEC', 'IMBIE', 'C2019']
lines = [Line2D([0], [0], color=c) for c in color]
plt.legend(lines, label)

# plt.legend()
plt.savefig('tmp/mb_cumsum_compare.png', transparent=False, bbox_inches='tight', dpi=300)
plt.savefig('tmp/mb_cumsum_compare.svg', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:



** DONE This vs. IMBIE/GRACE/SEC GIS XY

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
import scipy as sp
import scipy.stats as sps
from adjust_spines import adjust_spines as adj
import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)

# plt.close(1)

# ONE COLUMN: %\includegraphics[width=8.3cm]{FILE NAME}

fig = plt.figure(1, figsize=(3.26,7)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
axGRACE = fig.add_subplot(311)
axSEC = fig.add_subplot(312)
axIMBIE = fig.add_subplot(313)

# this
this_mb = xr.open_dataset('./TMB/mb_sector.nc')\
            .resample({'time':'YS'})\
            .sum()['mb']


if 'gmb' not in locals():
    <<load_GRACE>>
    gmb = gmb['GMB_sector'].sum(dim='cell')\
                           .resample({'time':'YS'})\
                           .mean()
    gmb = gmb.diff(dim='time')
    this_mb_gmb = this_mb.sel({'time':slice(gmb.time[0], gmb.time[-1])})    

if 'sec' not in locals():
    <<load_SEC>>
    sec = sec['SEC'].sum(dim='sector')\
                    .resample({'time':'YS'})\
                    .sum()
    this_mb_sec = this_mb.sel({'time':slice(sec.time[0], sec.time[-1])})    
    
if 'imbie' not in locals():
    <<load_imbie>>
    # imbie = imbie.resample('1D').mean().interpolate(method='time')
    imbie = imbie.resample('YS').mean()
    imbie = imbie['mb']
    imbie = imbie[imbie.index.year > 1986]
    imbie = imbie.dropna()
    this_mb_imbie = this_mb.sel({'time':slice(imbie.index[0], imbie.index[-1])})
    
# graphics
def my_plot(ax, x, y):

    if type(x) == xr.core.dataarray.DataArray:
        years = x.time.dt.year.values
    else:
        years = x.index.year.values
        
    print(years)
    color = years - min(years); color = color / max(color)
    y2str = [_[2:4] for _ in years.astype(str)]

    # https://stackoverflow.com/questions/51034408/how-to-make-the-color-of-one-end-of-colorbar-darker-in-matplotlib
    cmap = cm.viridis(color)
    cmap = mpl.colors.ListedColormap(cmap[:-3,:-1])

    scatter = ax.scatter(x.values, y.values, alpha=0, c=color, cmap=cmap)
    for i,s in enumerate(y2str):
        ax.text(x.values[i], y.values[i], s,
                c = cmap(color)[i],
                fontsize=10,
                fontweight='bold',
                horizontalalignment='center',
                verticalalignment='center')

    if ax == axGRACE:
        ax.set_ylabel('GRACE\n[Gt yr$^{-1}$]', labelpad=-25)
    if ax == axSEC:
        ax.set_ylabel('SEC', labelpad=-25)
    if ax == axIMBIE:
        ax.set_ylabel('IMBIE', labelpad=-25)
        ax.set_xlabel('M2021\n[Gt yr$^{-1}$]', labelpad=-7)
    
    ax.set_xticks([-400,200])
    ax.set_yticks(ax.get_xticks())
    ax.set_xlim(ax.get_xticks()[[0,-1]])
    ax.set_ylim(ax.get_xlim())

    slope, intercept, r_value, p_value, std_err = sps.linregress(x.values, y.values)
    bias = np.mean(x.values - y.values)
    # np.sqrt(np.mean((predictions-targets)**2))
    rmse = np.sqrt(np.mean((x.values - y.values)**2))
    # ax.plot(x, slope * x + intercept, 'k', linewidth=0.5)
    ax.text(1.0, -0.03,
            "r: %.2f\nbias: %.1f\nrmse: %.1f"
            % (round(r_value,2), round(bias,1), round(rmse,2)),
            transform=ax.transAxes,
            horizontalalignment='right',
            fontsize=9)

    ax.plot(ax.get_xlim(), ax.get_ylim(), color='k', alpha=0.25, linestyle='--')
    adj(ax, ['left','bottom'])
    return scatter


s = my_plot(axGRACE, this_mb_gmb, gmb)
s = my_plot(axSEC, this_mb_sec, sec)
s = my_plot(axIMBIE,  this_mb_imbie, imbie)

plt.savefig('tmp/this_v_grace_sec_imbie.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:
: [2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016
:  2017 2018 2019 2020]
: [1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005
:  2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019]
: [1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005
:  2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018]

[[./tmp/this_v_grace_sec_imbie.png]]


** DONE This vs. Mouginot (2019): GIS xy

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
from adjust_spines import adjust_spines as adj
import scipy.stats as sps

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)

# plt.close(1)
fig = plt.figure(1, figsize=(3.26,7)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
axSMB = fig.add_subplot(311)
axD = fig.add_subplot(312)
axMB = fig.add_subplot(313)

# Mouginot SMB, D, and MB (Mouginot, 2019)
<<load_mouginot>>

# this
this_smb = xr.open_dataset('./tmp/smb.nc')\
             .resample({'time':'YS'})\
             .sum()

<<load_mmb>>
this_D = mmb.resample({'time':'YS'})\
            .sum()

this_mb = xr.open_dataset('./TMB/mb_sector.nc')\
            .resample({'time':'YS'})\
            .sum()

mouginot = mouginot.where(mouginot['time'].dt.year >= 1987).dropna(dim='time')
this_smb = this_smb.where((this_smb['time'].dt.year <= 2018) & (this_smb['time'].dt.year >= 1987)).dropna(dim='time')
this_D = this_D.where((this_D['time'].dt.year <= 2018) & (this_D['time'].dt.year >= 1987)).dropna(dim='time')
this_mb = this_mb.where((this_mb['time'].dt.year <= 2018) & (this_mb['time'].dt.year >= 1987)).dropna(dim='time')

# graphics
def my_plot(ax, x, y):

    years = x.time.dt.year.values
    color = years - min(years); color = color / max(color)
    y2str = [_[2:4] for _ in years.astype(str)]

    # https://stackoverflow.com/questions/51034408/how-to-make-the-color-of-one-end-of-colorbar-darker-in-matplotlib
    cmap = cm.viridis(color)
    cmap = mpl.colors.ListedColormap(cmap[:-3,:-1])

    scatter = ax.scatter(x.values, y.values, alpha=0, c=color, cmap=cmap)
    for i,s in enumerate(y2str):
        ax.text(x.values[i], y.values[i], s,
                c = cmap(color)[i],
                fontsize=10,
                fontweight='bold',
                horizontalalignment='center',
                verticalalignment='center')

    if ax == axSMB:
        ax.text(0, 0.9, 'SMB', transform=ax.transAxes)
        ax.set_xticks([0,600])
        ax.set_ylabel('M2019\n[Gt yr$^{-1}$]', labelpad=-25)
    if ax == axD:
        ax.text(0, 0.9, 'MMB [+ BMB]', transform=ax.transAxes)
        ax.set_xticks([0,600])
    if ax == axMB:
        ax.text(0, 0.9, 'MB', transform=ax.transAxes)
        ax.set_xticks([-400, 0, 200])
        ax.set_xlabel('M2021\n[Gt yr$^{-1}$]')

    ax.set_yticks(ax.get_xticks())
    ax.set_xlim(ax.get_xticks()[[0,-1]])
    ax.set_ylim(ax.get_xlim())
        
    slope, intercept, r_value, p_value, std_err = sps.linregress(x.values, y.values)
    bias = np.mean(x.values - y.values)
    # np.sqrt(np.mean((predictions-targets)**2))
    rmse = np.sqrt(np.mean((x.values - y.values)**2))
    # ax.plot(x, slope * x + intercept, 'k', linewidth=0.5)
    ax.text(1.0, -0.03, "r: %.2f\nbias: %.1f\nrmse: %.1f" % (round(r_value,2), round(bias,1), round(rmse,2)),
            transform=ax.transAxes,
            horizontalalignment='right',
            fontsize=9)

    ax.plot(ax.get_xlim(), ax.get_ylim(), color='k', alpha=0.25, linestyle='--')
    adj(ax, ['left','bottom'])
    return scatter


my_plot(axSMB, mouginot['SMB'].sum(dim='region'), this_smb['smb'])
my_plot(axD,   mouginot['D'].sum(dim='region'), this_D['mmb'])
s = my_plot(axMB,  mouginot['MB'].sum(dim='region'), this_mb['mb'])


# https://stackoverflow.com/questions/17478165/
def axis_to_fig(axis):
    fig = axis.figure
    def transform(coord):
        return fig.transFigure.inverted().transform(
            axis.transAxes.transform(coord))
    return transform

def add_sub_axes(axis, rect):
    fig = axis.figure
    left, bottom, width, height = rect
    trans = axis_to_fig(axis)
    figleft, figbottom = trans((left, bottom))
    figwidth, figheight = trans([width,height]) - trans([0,0])
    return fig.add_axes([figleft, figbottom, figwidth, figheight])

# axCB = add_sub_axes(axMB, [1.1, 0.0, 0.075, 1])
axCB = add_sub_axes(axMB, [0.0, -0.75, 1, 0.075])
cb = plt.colorbar(s, cax=axCB, orientation='horizontal', ticks=[0,1])
cb.set_alpha(1) # https://stackoverflow.com/questions/4478725/
cb.draw_all()
cb.ax.xaxis.set_ticks_position('top')
cb.ax.xaxis.set_label_position('top')
# cb.set_label("Time [year]", labelpad=-20)
axCB.set_xticklabels(mouginot['time'].dt.year[[0,-1]].values)

plt.savefig('tmp/mouginot_2019.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:
#+begin_example
<ipython-input-84-0854dbe8b3f5>:28: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.
  df = pd.read_excel('/home/kdm/data/Mouginot_2019/pnas.1904242116.sd02.xlsx', sheet_name=1)
<ipython-input-84-0854dbe8b3f5>:36: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ds['time'] = (('time'), pd.to_datetime(df.iloc[r0-1][df.columns[c0:(c1 + 1)]].astype(np.int).values, format="%Y"))
<ipython-input-84-0854dbe8b3f5>:38: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ds['D'] = (('time','region'), df.iloc[r0:r1][df.columns[c0:(c1 + 1)]].values.T.astype(np.float))
<ipython-input-84-0854dbe8b3f5>:41: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ds['D_err'] = (('time','region'), df.iloc[r0:r1][df.columns[c2:(c3 + 1)]].values.T.astype(np.float))
<ipython-input-84-0854dbe8b3f5>:44: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ds['SMB'] = (('time','region'), df.iloc[r0:r1][df.columns[c0:(c1 + 1)]].values.T.astype(np.float))
<ipython-input-84-0854dbe8b3f5>:45: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ds['SMB_err'] = (('time','region'), df.iloc[r0:r1][df.columns[c2:(c3 + 1)]].values.T.astype(np.float))
<ipython-input-84-0854dbe8b3f5>:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ds['MB'] = (('time','region'), df.iloc[r0:r1][df.columns[c0:(c1 + 1)]].values.T.astype(np.float))
<ipython-input-84-0854dbe8b3f5>:49: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ds['MB_err'] = (('time','region'), df.iloc[r0:r1][df.columns[c2:(c3 + 1)]].values.T.astype(np.float))
<ipython-input-84-0854dbe8b3f5>:198: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig('tmp/mouginot_2019.png', transparent=False, bbox_inches='tight', dpi=300)
#+end_example


[[./tmp/mouginot_2019.png]]

** DONE This vs. Colgan (2019): GIS xy

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
import scipy as sp
import scipy.stats as sps
from adjust_spines import adjust_spines as adj
import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)

# plt.close(1)
fig = plt.figure(1, figsize=(3.26,7)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
axSMB = fig.add_subplot(311)
axD = fig.add_subplot(312)
axMB = fig.add_subplot(313)

# PROMICE MB (Colgan 2019)
<<load_PROMICE_MB>>

# this
this_smb = xr.open_dataset('./tmp/smb.nc')\
             .resample({'time':'YS'})\
             .sum()\
             .reindex(time=promice['time'])

<<load_mmb>>
this_D = mmb.resample({'time':'YS'})\
            .sum()\
            .reindex(time=promice['time'])

this_mb = xr.open_dataset('./TMB/mb_sector.nc')\
            .resample({'time':'YS'})\
            .sum()\
           .reindex(time=promice['time'])

# graphics
def my_plot(ax, x, y):

    years = x.time.dt.year.values
    color = years - min(years); color = color / max(color)
    y2str = [_[2:4] for _ in years.astype(np.str)]

    # https://stackoverflow.com/questions/51034408/how-to-make-the-color-of-one-end-of-colorbar-darker-in-matplotlib
    cmap = cm.viridis(color)
    cmap = mpl.colors.ListedColormap(cmap[:-3,:-1])

    scatter = ax.scatter(x.values, y.values, alpha=0, c=color, cmap=cmap)
    for i,s in enumerate(y2str):
        ax.text(x.values[i], y.values[i], s,
                c = cmap(color)[i],
                fontsize=10,
                fontweight='bold',
                horizontalalignment='center',
                verticalalignment='center')

    if ax == axSMB:
        ax.text(0, 0.9, 'SMB', transform=ax.transAxes)
        ax.set_xticks([0,600])
        ax.set_ylabel('C2019\n[Gt yr$^{-1}$]', labelpad=-25)
    if ax == axD:
        ax.text(0, 0.9, 'MMB [+ BMB]', transform=ax.transAxes)
        ax.set_xticks([0,600])
    if ax == axMB:
        ax.text(0, 0.9, 'MB', transform=ax.transAxes)
        ax.set_xticks([-400, 0, 200])
        ax.set_xlabel('M2021\n[Gt yr$^{-1}$]')

    ax.set_yticks(ax.get_xticks())
    ax.set_xlim(ax.get_xticks()[[0,-1]])
    ax.set_ylim(ax.get_xlim())

    slope, intercept, r_value, p_value, std_err = sps.linregress(x.values, y.values)
    bias = np.mean(x.values - y.values)
    # np.sqrt(np.mean((predictions-targets)**2))
    rmse = np.sqrt(np.mean((x.values - y.values)**2))
    # ax.plot(x, slope * x + intercept, 'k', linewidth=0.5)
    ax.text(1.0, -0.03, "r: %.2f\nbias: %.1f\nrmse: %.1f" % (round(r_value,2), round(bias,1), round(rmse,2)),
            transform=ax.transAxes,
            horizontalalignment='right',
            fontsize=9)

    ax.plot(ax.get_xlim(), ax.get_ylim(), color='k', alpha=0.25, linestyle='--')
    adj(ax, ['left','bottom'])
    return scatter

my_plot(axSMB, this_smb['smb'], promice['SMB'].sum(dim='sector'))
my_plot(axD,   this_D['mmb'],   promice['D'].sum(dim='sector'))
s = my_plot(axMB,  this_mb['mb'], promice['MB'].sum(dim='sector'))

# https://stackoverflow.com/questions/17478165/
def axis_to_fig(axis):
    fig = axis.figure
    def transform(coord):
        return fig.transFigure.inverted().transform(
            axis.transAxes.transform(coord))
    return transform

def add_sub_axes(axis, rect):
    fig = axis.figure
    left, bottom, width, height = rect
    trans = axis_to_fig(axis)
    figleft, figbottom = trans((left, bottom))
    figwidth, figheight = trans([width,height]) - trans([0,0])
    return fig.add_axes([figleft, figbottom, figwidth, figheight])

# axCB = add_sub_axes(axMB, [1.1, 0.0, 0.075, 1])
axCB = add_sub_axes(axMB, [0.0, -0.75, 1, 0.075])
cb = plt.colorbar(s, cax=axCB, orientation='horizontal', ticks=[0,1])
cb.set_alpha(1) # https://stackoverflow.com/questions/4478725/
cb.draw_all()
cb.ax.xaxis.set_ticks_position('top')
cb.ax.xaxis.set_label_position('top')
# cb.set_label("Time [year]", labelpad=-20)
axCB.set_xticklabels(mouginot['time'].dt.year[[0,-1]].values)

plt.savefig('tmp/colgan_2019.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:
#+begin_example
<ipython-input-90-fb0055b48a63>:26: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.
  df_all = pd.read_excel("/home/kdm/data/Colgan_2019/MassBalance_07022019.xlsx", index_col=0, sheet_name=sheet)
<ipython-input-90-fb0055b48a63>:123: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  y2str = [_[2:4] for _ in years.astype(np.str)]
<ipython-input-90-fb0055b48a63>:123: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  y2str = [_[2:4] for _ in years.astype(np.str)]
<ipython-input-90-fb0055b48a63>:123: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  y2str = [_[2:4] for _ in years.astype(np.str)]
<ipython-input-90-fb0055b48a63>:198: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig('tmp/colgan_2019.png', transparent=False, bbox_inches='tight', dpi=300)
#+end_example

[[./tmp/colgan_2019.png]]


** DONE HIRHAM MAR RACMO timeseries
#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
from adjust_spines import adjust_spines as adj

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)

# plt.close(1)
fig = plt.figure(1, figsize=(8,8)) # w,h
fig.clf()
fig.set_tight_layout(True)
ax = fig.add_subplot(311)

C = 'k'; L='-'
C_HIRHAM = 'gray'; L_HIRHAM='--'
C_MAR = 'blue'; L_MAR = ':'
C_RACMO = 'red'; L_RACMO = '-'

# MB (this)
mb = xr.open_dataset("./TMB/mb_sector.nc")

mb = mb.sum(dim='sector')

kw = {'ax':ax, 'legend':False, 'drawstyle':'steps-post'}

mb_ann = mb.to_dataframe()\
           .resample('AS')\
           .sum()\
           .rename(columns={'mb':'M2021',
                            'mb_HIRHAM':'HIRHAM',
                            'mb_MAR':'MAR',
                            'mb_RACMO':'RACMO'})
mb_ann['M2021'].plot(color=C, linestyle=L, **kw)
mb_ann['HIRHAM'].plot(color=C_HIRHAM, linestyle=L_HIRHAM, **kw)
mb_ann['MAR'].plot(color=C_MAR, linestyle=L_MAR, **kw)
mb_ann['RACMO'].plot(color=C_RACMO, linestyle=L_RACMO, **kw)

# ax.fill_between(mb_ann.index, mb_ann.values.flatten(), color='k', alpha=0.1, step='post')

plt.legend(loc='lower left')



ax2 = fig.add_subplot(312)
mb = mb.sel({'time':slice('2019-01-01','2019-12-31')})
kw = {'ax': ax2, 'drawstyle':'steps-post'}

mb['mb'].plot(color=C, linestyle=L, **kw)
mb['mb_HIRHAM'].plot(color=C_HIRHAM, linestyle=L_HIRHAM, **kw)
mb['mb_MAR'].plot(color=C_MAR, linestyle=L_MAR, **kw)
mb['mb_RACMO'].plot(color=C_RACMO, linestyle=L_RACMO, **kw)


ax3 = fig.add_subplot(313)
kw = {'ax': ax3, 'drawstyle':'steps-post'}

(mb['mb_HIRHAM']-mb['mb']).plot(color=C_HIRHAM, linestyle=L_HIRHAM, **kw)
(mb['mb_MAR']-mb['mb']).plot(color=C_MAR, linestyle=L_MAR, **kw)
(mb['mb_RACMO']-mb['mb']).plot(color=C_RACMO, linestyle=L_RACMO, **kw)

ax.set_ylabel("Mass gain [Gt yr$^{-1}$]")
ax.set_xlabel("")
adj(ax, ['left','bottom'])

ax2.set_xlabel("Time [Year]")
ax2.set_ylabel("Mass gain [Gt d$^{-1}$]")
adj(ax2, ['left','bottom'])

ax3.set_xlabel("Time [Year]")
ax3.set_ylabel("Difference [Gt d$^{-1}$]")
adj(ax3, ['left','bottom'])

plt.savefig('tmp/mb_3RCM.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:

** NOTDONE SMB timeseries

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)

n = 3
color = plt.cm.viridis(np.linspace(0.1,0.9,n)) # This returns RGBA; convert:
hexcolor = map(lambda rgb:'#%02x%02x%02x' % (np.int(rgb[0]*255),np.int(rgb[1]*255),np.int(rgb[2]*255)),
               tuple(color[:,0:-1]))
mpl.rcParams['axes.prop_cycle'] = cycler('color' , hexcolor)

fig = plt.figure(1, figsize=(5,4)) # w,h
fig.clf()
fig.set_tight_layout(True)
ax = fig.add_subplot(111)

# MB (this)
smb = xr.open_dataset("./tmp/smb.nc")
smb['HIRHAM_region'].sum(dim='region').to_dataframe(name='HIRHAM').cumsum()[::-1].plot(ax=ax)
smb['MAR_region'].sum(dim='region').to_dataframe(name='MAR').cumsum()[::-1].plot(ax=ax)
smb['RACMO_region'].sum(dim='region').to_dataframe(name='RACMO').cumsum()[::-1].plot(ax=ax)

kw_err = {'linestyle' : '--',
          'legend' : False}

ax.set_ylabel("Mass [Gt]")
ax.set_xlabel("Time [Year]")

plt.legend()
plt.savefig('tmp/smb_3.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:

** INPROGRESS TMB violin SMB+ SMB-

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
from adjust_spines import adjust_spines as adj
import seaborn as sns

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

# n = 4
# color = plt.cm.viridis(np.linspace(0.1,0.9,n)) # This returns RGBA; convert:
# hexcolor = map(lambda rgb:'#%02x%02x%02x' % (np.int(rgb[0]*255),np.int(rgb[1]*255),np.int(rgb[2]*255)),
#                tuple(color[:,0:-1]))
# mpl.rcParams['axes.prop_cycle'] = cycler('color' , hexcolor)

# plt.close(1)
fig = plt.figure(1, figsize=(8,3)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
ax = fig.add_subplot(111)


# MB (this)
mb = xr.open_dataset("./TMB/mb.nc")
# mb['mb'] = (('time'), mb[['HIRHAM_sector','MAR_sector','RACMO_sector']].sum(dim='sector'))
# https://stackoverflow.com/questions/60944525/calculate-mean-of-several-xarray-variables
mb['mb'] = mb[['HIRHAM_sector','MAR_sector','RACMO_sector']].sum(dim='sector').to_array(dim='new').mean('new')
# mb['mb'].to_dataframe(name='M2021').resample('AS').sum().plot(ax=ax, drawstyle='steps')

v = sns.violinplot(x=mb['time'].dt.year.values,
                   # y=mb['mb'].where(mb['mb'] > 0).values,
                   y=mb['mb'].values,
                   inner = None,
                   color = 'r',
                   alpha = 0.8, 
                   ax=ax)
# sns.violinplot(x=mb['time'].dt.year.values,
#                y=mb['mb'].where(mb['mb'] < 0).values,
#                inner = None,
#                color = 'lightblue',
#                alpha = 0.3,
#                ax=ax)

# mb['mb'].to_dataframe(name='M2021').resample('AS').sum().plot.bar(ax=ax, color='k', legend=False)
# ax.set_xticklabels([_.get_text()[0:4] for _ in ax.get_xticklabels()])

# ax.set_ylim([-400,200])
# # ax.set_yticks(ax.get_ylim())

# ax.set_ylabel("Annual mass gain [Gt]")
ax.set_xlabel("Time [Year]")

adj(ax, ['left','bottom'])
plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)

# plt.legend()
# plt.savefig('tmp/mb_violin.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC


** INPROGRESS TMB vs. others timeseries

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

n = 4
color = plt.cm.viridis(np.linspace(0.1,0.9,n)) # This returns RGBA; convert:
hexcolor = map(lambda rgb:'#%02x%02x%02x' % (np.int(rgb[0]*255),np.int(rgb[1]*255),np.int(rgb[2]*255)),
               tuple(color[:,0:-1]))
mpl.rcParams['axes.prop_cycle'] = cycler('color' , hexcolor)

# plt.close(1)
fig = plt.figure(1, figsize=(5,4)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
ax = fig.add_subplot(111)


# MB (this)
mb = xr.open_dataset("./TMB/mb.nc")
mb['HIRHAM_sector'].sum(dim='sector').to_dataframe(name='M2021 (HIRHAM)').resample('AS').sum().plot(ax=ax, drawstyle='steps')
mb['MAR_sector'].sum(dim='sector').to_dataframe(name='M2021 (MAR)').resample('AS').sum().plot(ax=ax, drawstyle='steps')
mb['RACMO_sector'].sum(dim='sector').to_dataframe(name='M2021 (RACMO)').resample('AS').sum().plot(ax=ax, drawstyle='steps')

# mb['HIRHAM_sector'].sum(dim='sector').to_dataframe(name='M2021 (HIRHAM)').resample('AS').sum().plot(ax=ax, drawstyle='steps')

kw_err = {'linestyle' : '--',
          'legend' : False}

# Mouginot
if 'mouginot' not in locals():
    <<load_mouginot>>
M = mouginot['MB'].sum(dim='region').to_dataframe('M2019')
M_err = mouginot['MB_err'].sum(dim='region').to_dataframe('M2019')
p = M.plot(ax=ax, label='Mouginot(2019)', drawstyle='steps')
# ax.fill_between(M.index, (M - M_err).values.T[0], (M + M_err).values.T[0], color=p.lines[-1].get_color(), alpha=0.25)
# (M-M_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (M+M_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)


# # IMBIE
# <<load_imbie>>
# imbie['mb_cum'] = imbie['mb_cum'] - 400 # offset
# p = imbie['mb_cum'].plot(ax=ax, label='IMBIE')
# ax.fill_between(imbie.index,
#                 imbie['mb_cum'] - imbie['mb_cum_err'],
#                 imbie['mb_cum'] + imbie['mb_cum_err'],
#                 color=p.lines[-1].get_color(),
#                 alpha=0.25)
# # (imbie['mb_cum'] - imbie['mb_cum_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# # (imbie['mb_cum'] + imbie['mb_cum_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)


# # SEC
# <<load_sec>>
# sec_sum = sec['SEC'].sum(dim='sector').to_dataframe(name='SEC').cumsum()
# sec_sum = sec_sum - 300
# p = sec_sum.plot(ax=ax, label='SEC')

# sec_err = sec['err'].sum(dim='sector').to_dataframe(name='SEC').cumsum()
# ax.fill_between(sec_err.index,
#                 (sec_sum - sec_err).values.flatten(),
#                 (sec_sum + sec_err).values.flatten(),
#                 color=p.lines[-1].get_color(),
#                 alpha=0.25)
# # (sec_sum - sec_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# # (sec_sum + sec_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)


# # GRACE
# <<load_grace>>
# gmb_sum = gmb['GMB_sector'].sum(dim='cell').to_dataframe(name="GRACE")
# gmb_sum = gmb_sum - 1700
# p = gmb_sum.plot(ax=ax, label='GRACE')

# gmb_err = gmb['err_sector'].sum(dim='cell').to_dataframe(name="GRACE")
# ax.fill_between(gmb_err.index,
#                 (gmb_sum - gmb_err).values.flatten(),
#                 (gmb_sum + gmb_err).values.flatten(),
#                 color=p.lines[-1].get_color(),
#                 alpha=0.25)
# # (gmb_sum - gmb_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# # (gmb_sum + gmb_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)



# # PROMICE MB (Colgan 2019)
# <<load_PROMICE_MB>>
# promice_sum = promice.sum(dim="sector").to_dataframe().cumsum()
# promice_sum["MB"] = promice_sum["MB"] - 500
# p = promice_sum["MB"].plot(ax=ax, label='C2019')
# ax.fill_between(promice_sum.index,
#                 promice_sum["MB"] - promice_sum["MB_err"],
#                 promice_sum["MB"] + promice_sum["MB_err"],
#                 color=p.lines[-1].get_color(),
#                 alpha=0.25)
# # (promice_sum['MB'] - promice_sum['MB_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# # (promice_sum['MB'] + promice_sum['MB_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)

ax.set_ylabel("Mass [Gt]")
ax.set_xlabel("Time [Year]")

plt.legend()
plt.savefig('tmp/mb_ts.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:
** TMB vs. GRACE

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

n = 6
color = plt.cm.viridis(np.linspace(0.1,0.9,n)) # This returns RGBA; convert:
hexcolor = map(lambda rgb:'#%02x%02x%02x' % (np.int(rgb[0]*255),np.int(rgb[1]*255),np.int(rgb[2]*255)),
               tuple(color[:,0:-1]))
mpl.rcParams['axes.prop_cycle'] = cycler('color' , hexcolor)



# plt.close(1)
fig = plt.figure(1, figsize=(5,4)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
ax = fig.add_subplot(111)


# MB (this)
mb = xr.open_dataset("./TMB/mb.nc")
mb['MAR_sector'].sum(dim='sector').to_dataframe(name='MAR - Mankoff(2020)').cumsum().plot(ax=ax)
mb['RACMO_sector'].sum(dim='sector').to_dataframe(name='RACMO - Mankoff(2020)').cumsum().plot(ax=ax)

H = mb['HIRHAM_sector'].sum(dim='sector').to_dataframe(name='HIRHAM - Mankoff(2020)').cumsum()
(H-350).plot(ax=ax)

# IMBIE
<<load_imbie>>
imbie['mb_cum'] = imbie['mb_cum'] - 400 # offset
p = imbie['mb_cum'].plot(ax=ax, label='IMBIE')
# ax.fill_between(imbie.index,
#                 imbie['mb_cum'] - imbie['mb_cum_err'],
#                 imbie['mb_cum'] + imbie['mb_cum_err'],
#                 color=p.lines[-1].get_color(),
#                 alpha=0.25)
# (imbie['mb_cum'] - imbie['mb_cum_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (imbie['mb_cum'] + imbie['mb_cum_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)


# SEC
<<load_sec>>
sec_sum = sec['SEC'].sum(dim='sector').to_dataframe(name='SEC').cumsum()
sec_sum = sec_sum - 300
p = sec_sum.plot(ax=ax, label='SEC')

sec_err = sec['err'].sum(dim='sector').to_dataframe(name='SEC').cumsum()
# ax.fill_between(sec_err.index,
#                 (sec_sum - sec_err).values.flatten(),
#                 (sec_sum + sec_err).values.flatten(),
#                 color=p.lines[-1].get_color(),
#                 alpha=0.25)
# (sec_sum - sec_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (sec_sum + sec_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)




# GRACE
<<load_grace>>
gmb_sum = gmb['GMB_sector'].sum(dim='cell').to_dataframe(name="GRACE")
gmb_sum = gmb_sum - 1700
p = gmb_sum.plot(ax=ax, label='GRACE')

gmb_err = gmb['err_sector'].sum(dim='cell').to_dataframe(name="GRACE")
ax.fill_between(gmb_err.index,
                (gmb_sum - gmb_err).values.flatten(),
                (gmb_sum + gmb_err).values.flatten(),
                color=p.lines[-1].get_color(),
                alpha=0.25)
# (gmb_sum - gmb_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (gmb_sum + gmb_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)



# # PROMICE MB (Colgan 2019)
# <<load_PROMICE_MB>>
# promice_sum = promice.sum(dim="sector").to_dataframe().cumsum()
# promice_sum["MB"] = promice_sum["MB"] - 500
# p = promice_sum["MB"].plot(ax=ax, label='Colgan (2019)')
# ax.fill_between(promice_sum.index,
#                 promice_sum["MB"] - promice_sum["MB_err"],
#                 promice_sum["MB"] + promice_sum["MB_err"],
#                 color=p.lines[-1].get_color(),
#                 alpha=0.25)
# # (promice_sum['MB'] - promice_sum['MB_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# # (promice_sum['MB'] + promice_sum['MB_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)

ax.set_ylabel("Mass [Gt]")
ax.set_xlabel("Time [Year]")

plt.legend()
plt.savefig('tmp/mb_BAMS.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:
** TMB vs. others timeseries: BACKWARD

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

n = 8
color = plt.cm.viridis(np.linspace(0.1,0.9,n)) # This returns RGBA; convert:
hexcolor = map(lambda rgb:'#%02x%02x%02x' % (np.int(rgb[0]*255),np.int(rgb[1]*255),np.int(rgb[2]*255)),
               tuple(color[:,0:-1]))
mpl.rcParams['axes.prop_cycle'] = cycler('color' , hexcolor)



# plt.close(1)
fig = plt.figure(1, figsize=(5,4)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
ax = fig.add_subplot(111)


# MB (this)
mb = xr.open_dataset("./TMB/mb.nc")
# mb['HIRHAM_sector'].sum(dim='sector').to_dataframe(name='HIRHAM - Mankoff(2020) [this]').cumsum().plot(ax=ax)
# mb['MAR_sector'].sum(dim='sector').to_dataframe(name='MAR - Mankoff(2020) [this]').cumsum().plot(ax=ax)
# mb['RACMO_sector'].sum(dim='sector').to_dataframe(name='RACMO - Mankoff(2020) [this]').cumsum().plot(ax=ax)

mb_GL = mb[['HIRHAM_sector','MAR_sector','RACMO_sector']]\
    .sum(dim='sector')\
    .rename_vars({'HIRHAM_sector':'H',
                  'MAR_sector':'M',
                  'RACMO_sector':'R'})

# mb_GL = mb_GL.cumsum(dim="time", keep_attrs=True)
# https://github.com/pydata/xarray/issues/3141
mb_GL = mb_GL.apply(lambda x: x.cumsum(dim='time'))

# for v in ['H','M','R']: mb_GL[v] = mb_GL[v] - mb_GL[v].sel(time=slice('2020-01-01','2020-09-30')).mean().values
for v in ['H','M','R']: mb_GL[v] = mb_GL[v] - mb_GL[v].isel(time=-365).values
mb_GL.to_dataframe().plot(ax=ax)
#+END_SRC

#+RESULTS:
: <AxesSubplot:xlabel='time'>

#+BEGIN_SRC jupyter-python
kw_err = {'linestyle' : '--',
          'legend' : False}

# Mouginot
<<load_mouginot>>
M = mouginot['MB'].sum(dim='region').to_dataframe('Mouginot (2019)').cumsum()
M_err = mouginot['MB_err'].sum(dim='region').to_dataframe('Mouginot (2019)').cumsum()
p = M.plot(ax=ax, label='Mouginot(2019)')
ax.fill_between(M.index, (M - M_err).values.T[0], (M + M_err).values.T[0], color=p.lines[-1].get_color(), alpha=0.25)
# (M-M_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (M+M_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)


# IMBIE
<<load_imbie>>
imbie['mb_cum'] = imbie['mb_cum'] - 400 # offset
p = imbie['mb_cum'].plot(ax=ax, label='IMBIE')
ax.fill_between(imbie.index,
                imbie['mb_cum'] - imbie['mb_cum_err'],
                imbie['mb_cum'] + imbie['mb_cum_err'],
                color=p.lines[-1].get_color(),
                alpha=0.25)
# (imbie['mb_cum'] - imbie['mb_cum_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (imbie['mb_cum'] + imbie['mb_cum_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)


# SEC
<<load_sec>>
sec_sum = sec['SEC'].sum(dim='sector').to_dataframe(name='SEC').cumsum()
sec_sum = sec_sum - 300
p = sec_sum.plot(ax=ax, label='SEC')

sec_err = sec['err'].sum(dim='sector').to_dataframe(name='SEC').cumsum()
ax.fill_between(sec_err.index,
                (sec_sum - sec_err).values.flatten(),
                (sec_sum + sec_err).values.flatten(),
                color=p.lines[-1].get_color(),
                alpha=0.25)
# (sec_sum - sec_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (sec_sum + sec_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)




# GRACE
<<load_grace>>
gmb_sum = gmb['GMB_sector'].sum(dim='cell').to_dataframe(name="GRACE")
gmb_sum = gmb_sum - 1700
p = gmb_sum.plot(ax=ax, label='GRACE')

gmb_err = gmb['err_sector'].sum(dim='cell').to_dataframe(name="GRACE")
ax.fill_between(gmb_err.index,
                (gmb_sum - gmb_err).values.flatten(),
                (gmb_sum + gmb_err).values.flatten(),
                color=p.lines[-1].get_color(),
                alpha=0.25)
# (gmb_sum - gmb_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (gmb_sum + gmb_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)



# PROMICE MB (Colgan 2019)
<<load_PROMICE_MB>>
promice_sum = promice.sum(dim="sector").to_dataframe().cumsum()
promice_sum["MB"] = promice_sum["MB"] - 500
p = promice_sum["MB"].plot(ax=ax, label='Colgan (2019)')
ax.fill_between(promice_sum.index,
                promice_sum["MB"] - promice_sum["MB_err"],
                promice_sum["MB"] + promice_sum["MB_err"],
                color=p.lines[-1].get_color(),
                alpha=0.25)
# (promice_sum['MB'] - promice_sum['MB_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (promice_sum['MB'] + promice_sum['MB_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)



ax.invert_xaxis()
ax.set_ylabel("Mass [Gt]")
ax.set_xlabel("Time [Year]")

plt.legend()
plt.savefig('tmp/mb.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:

** TMB annual cycle

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)

n = (2020-1986)
color = plt.cm.viridis(np.linspace(0.1,0.9,n)) # This returns RGBA; convert:
hexcolor = map(lambda rgb:'#%02x%02x%02x' % (np.int(rgb[0]*255),np.int(rgb[1]*255),np.int(rgb[2]*255)),
               tuple(color[:,0:-1]))
mpl.rcParams['axes.prop_cycle'] = cycler('color' , hexcolor)



# plt.close(1)
fig = plt.figure(1, figsize=(5,4)) # w,h
fig.clf()
fig.set_tight_layout(True)
ax = fig.add_subplot(111)


# MB (this)
mb = xr.open_dataset("./TMB/mb.nc")

mb_GL = mb[['HIRHAM_sector','MAR_sector','RACMO_sector']]\
    .sum(dim='sector')\
    .rename_vars({'HIRHAM_sector':'H',
                  'MAR_sector':'M',
                  'RACMO_sector':'R'})\

# mb_GL = mb_GL.cumsum(dim="time", keep_attrs=True)
# https://github.com/pydata/xarray/issues/3141
# mb_GL = mb_GL.apply(lambda x: x.cumsum(dim='time'))

# # for v in ['H','M','R']: mb_GL[v] = mb_GL[v] - mb_GL[v].sel(time=slice('2020-01-01','2020-09-30')).mean().values
# for v in ['H','M','R']: mb_GL[v] = mb_GL[v] - mb_GL[v].isel(time=-365).values
# mb_GL.to_dataframe().plot(ax=ax)

for y in np.unique(mb_GL['time'].dt.year.values):
    mb_Y = mb_GL['M'].sel(time=slice(str(y)+'-09-01',str(y+1)+'-08-31'))
    y = mb_Y.to_dataframe().cumsum().values.flatten()
    x = np.arange(size(y))
    ax.plot(x,y, alpha=1)

    
<<load_grace>>
gmb_sum = gmb['GMB_sector'].sum(dim='cell').to_dataframe(name="GRACE")
for y in np.unique(gmb_sum.index.year.values):
    gmb_Y = gmb_sum['GRACE'][(gmb_sum.index > str(y)+'-09-01') & (gmb_sum.index < str(y+1)+'-08-31')]
    y = gmb_Y.values.flatten()
    y = y - y[0]
    x = np.linspace(0,365, size(y))
    ax.plot(x,y, alpha=1, color='k')
# gmb_sum = gmb_sum - 1700
# p = gmb_sum.plot(ax=ax, label='GRACE')

# gmb_err = gmb['err_sector'].sum(dim='cell').to_dataframe(name="GRACE")
# ax.fill_between(gmb_err.index,
#                 (gmb_sum - gmb_err).values.flatten(),
#                 (gmb_sum + gmb_err).values.flatten(),
#                 color=p.lines[-1].get_color(),
#                 alpha=0.25)


# mb['HIRHAM_sector'].sum(dim='sector').to_dataframe(name='HIRHAM - Mankoff(2020) [this]').cumsum().plot(ax=ax)
# mb['MAR_sector'].sum(dim='sector').to_dataframe(name='MAR - Mankoff(2020) [this]').cumsum().plot(ax=ax)
# mb['RACMO_sector'].sum(dim='sector').to_dataframe(name='RACMO - Mankoff(2020) [this]').cumsum().plot(ax=ax)

# kw_err = {'linestyle' : '--',
#           'legend' : False}


#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
# Mouginot
<<load_mouginot>>
M = mouginot['MB'].sum(dim='region').to_dataframe('Mouginot (2019)').cumsum()
M_err = mouginot['MB_err'].sum(dim='region').to_dataframe('Mouginot (2019)').cumsum()
p = M.plot(ax=ax, label='Mouginot(2019)')
ax.fill_between(M.index, (M - M_err).values.T[0], (M + M_err).values.T[0], color=p.lines[-1].get_color(), alpha=0.25)
# (M-M_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (M+M_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)


# IMBIE
<<load_imbie>>
imbie['mb_cum'] = imbie['mb_cum'] - 400 # offset
p = imbie['mb_cum'].plot(ax=ax, label='IMBIE')
ax.fill_between(imbie.index,
                imbie['mb_cum'] - imbie['mb_cum_err'],
                imbie['mb_cum'] + imbie['mb_cum_err'],
                color=p.lines[-1].get_color(),
                alpha=0.25)
# (imbie['mb_cum'] - imbie['mb_cum_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (imbie['mb_cum'] + imbie['mb_cum_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)


# SEC
<<load_sec>>
sec_sum = sec['SEC'].sum(dim='sector').to_dataframe(name='SEC').cumsum()
sec_sum = sec_sum - 300
p = sec_sum.plot(ax=ax, label='SEC')

sec_err = sec['err'].sum(dim='sector').to_dataframe(name='SEC').cumsum()
ax.fill_between(sec_err.index,
                (sec_sum - sec_err).values.flatten(),
                (sec_sum + sec_err).values.flatten(),
                color=p.lines[-1].get_color(),
                alpha=0.25)
# (sec_sum - sec_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (sec_sum + sec_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)




# GRACE
<<load_grace>>
gmb_sum = gmb['GMB_sector'].sum(dim='cell').to_dataframe(name="GRACE")
gmb_sum = gmb_sum - 1700
p = gmb_sum.plot(ax=ax, label='GRACE')

gmb_err = gmb['err_sector'].sum(dim='cell').to_dataframe(name="GRACE")
ax.fill_between(gmb_err.index,
                (gmb_sum - gmb_err).values.flatten(),
                (gmb_sum + gmb_err).values.flatten(),
                color=p.lines[-1].get_color(),
                alpha=0.25)
# (gmb_sum - gmb_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (gmb_sum + gmb_err).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)



# PROMICE MB (Colgan 2019)
<<load_PROMICE_MB>>
promice_sum = promice.sum(dim="sector").to_dataframe().cumsum()
promice_sum["MB"] = promice_sum["MB"] - 500
p = promice_sum["MB"].plot(ax=ax, label='Colgan (2019)')
ax.fill_between(promice_sum.index,
                promice_sum["MB"] - promice_sum["MB_err"],
                promice_sum["MB"] + promice_sum["MB_err"],
                color=p.lines[-1].get_color(),
                alpha=0.25)
# (promice_sum['MB'] - promice_sum['MB_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)
# (promice_sum['MB'] + promice_sum['MB_err']).plot(ax=ax, color=p.lines[-1].get_color(), **kw_err)

ax.set_ylabel("Mass [Gt]")
ax.set_xlabel("Time [Year]")

plt.legend()
plt.savefig('tmp/mb.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:

** This vs. Colgan (2019): Sectors xy

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
import matplotlib.gridspec as gridspec
import matplotlib.pyplot as plt
from matplotlib import rc
from adjust_spines import adjust_spines as adj
import scipy as sp
import scipy.stats as sps

rc('font', size=9)
rc('text', usetex=False)

# plt.close(1)
fig = plt.figure(1, figsize=((12/2.54),(22/2.54))) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# gs = gridspec.GridSpec(ncols=3, nrows=19, figure=fig) #w,h
gs = gridspec.GridSpec(ncols=3, nrows=8, figure=fig) #w,h

# PROMICE MB (Colgan 2019)
<<load_PROMICE_MB>>

# this
this_smb = xr.open_dataset('./tmp/smb.nc')\
             .resample({'time':'YS'})\
             .sum()\
             .reindex(time=promice['time'])

<<load_mmb>>
this_D = mmb.resample({'time':'YS'})\
            .sum()\
            .reindex(time=promice['time'])

this_mb = xr.open_dataset('./TMB/mb.nc')\
            .resample({'time':'YS'})\
            .sum()\
            .reindex(time=promice['time'])


# collapse all Wally sectors to just super-sectors
promice['Z'] = (('sector'), (promice.sector.values/10).astype(np.int))
promice = promice.groupby('Z').sum().rename({'Z':'sector'})
this_smb['Z'] = (('sector'), (this_smb.sector.values/10).astype(np.int))
this_smb = this_smb.groupby('Z').sum().rename({'Z':'sector'})
this_D['Z'] = (('sector'), (this_D.sector.values/10).astype(np.int))
this_D = this_D.groupby('Z').sum().rename({'Z':'sector'})
this_mb['Z'] = (('sector'), (this_mb.sector.values/10).astype(np.int))
this_mb = this_mb.groupby('Z').sum().rename({'Z':'sector'})

sector = this_mb['sector']

<<round_axes>>

def my_plot(ax, x, y):
    years = x.time.dt.year.values
    color = years - min(years); color = color / max(color)
    y2str = [_[2:4] for _ in years.astype(np.str)]

    # https://stackoverflow.com/questions/51034408/how-to-make-the-color-of-one-end-of-colorbar-darker-in-matplotlib
    cmap = cm.viridis(color)
    cmap = mpl.colors.ListedColormap(cmap[:-3,:-1])

    scatter = ax.scatter(x.values, y.values, alpha=0.75, c=color, cmap=cmap, clip_on=False)
        
    if x.sector.values == 1:
        if ax == axSMB: ax.set_title('SMB')
        if ax == axD: ax.set_title('MMB + BMB')
        if ax == axMB: ax.set_title('MB')

    if (ax == axSMB):
        ax.set_ylabel(x.sector.values)
        if (x.sector.values == 8):
            ax.set_xlabel('C$_{2019}$ [Gt yr$^{-1}$]')
            ax.set_ylabel(ax.get_ylabel() + '\nThis [Gt yr$^{-1}$]')

    slope, intercept, r_value, p_value, std_err = sps.linregress(x.values, y.values)
    # ax.plot(x, slope * x + intercept, 'k', linewidth=0.5)
    ax.text(0.66, 0,
            "s: %.1f\ni: %.1f" % (round(slope,1), round(intercept,1)),
            transform=ax.transAxes,
            fontsize=8)

    ax.set_xticks(round_axes(ax.get_xlim(), ax.get_ylim()))
    ax.set_ylim(ax.get_xlim())
    ax.set_yticks(ax.get_xlim())
        
    ax.plot(ax.get_xlim(), ax.get_ylim(), color='k', alpha=0.25, linestyle='--')
    adj(ax, ['left','bottom'])
    return scatter


# graphics
for row in np.arange(8):
    axSMB = fig.add_subplot(gs[row,0])
    axD = fig.add_subplot(gs[row,1])
    axMB = fig.add_subplot(gs[row,2])

    my_plot(axSMB,
            promice['SMB'].sel({'sector':sector[row]}),
            this_smb['MAR_sector'].sel({'sector':sector[row]}))
    

    if (sector[row] != 14) & (sector[row] != 22):
        my_plot(axD,
                promice['D'].sel({'sector':sector[row]}),
                this_D['D_sector'].sel({'sector':sector[row]}))

    s = my_plot(axMB,
                promice['MB'].sel({'sector':sector[row]}),
                this_mb['MAR_sector'].sel({'sector':sector[row]}))

# https://stackoverflow.com/questions/17478165/
def axis_to_fig(axis):
    fig = axis.figure
    def transform(coord):
        return fig.transFigure.inverted().transform(
            axis.transAxes.transform(coord))
    return transform

def add_sub_axes(axis, rect):
    fig = axis.figure
    left, bottom, width, height = rect
    trans = axis_to_fig(axis)
    figleft, figbottom = trans((left, bottom))
    figwidth, figheight = trans([width,height]) - trans([0,0])
    return fig.add_axes([figleft, figbottom, figwidth, figheight])

axCB = add_sub_axes(axD, [0, -1, 1, 0.1])
cb = plt.colorbar(s, cax=axCB, orientation='horizontal', ticks=[0,1])
cb.set_alpha(1) # https://stackoverflow.com/questions/4478725/
cb.draw_all()
axCB.set_xticklabels(promice['time'].dt.year[[0,-1]].values)
    
# plt.legend()
plt.savefig('tmp/colgan_2019_sectors.png', transparent=False, bbox_inches='tight', dpi=150)
#+END_SRC

#+RESULTS:
: <ipython-input-352-bb2cbdc4a7d2>:217: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
:   plt.savefig('tmp/colgan_2019_sectors.png', transparent=False, bbox_inches='tight', dpi=150)

[[./tmp/colgan_2019_sectors.png]]

** INPROGRESS This vs. Colgan (2019): GIS ts

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)

# plt.close(1)
fig = plt.figure(1, figsize=(8,2.5)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
axSMB = fig.add_subplot(131)
axD = fig.add_subplot(132)
axMB = fig.add_subplot(133)

# PROMICE MB (Colgan 2019)
<<load_PROMICE_MB>>

# this
this_smb = xr.open_dataset('./tmp/smb.nc')\
             .resample({'time':'YS'})\
             .sum()\
             .reindex(time=promice['time'])

<<load_mmb>>
this_D = mmb.resample({'time':'YS'})\
            .sum()\
            .reindex(time=promice['time'])

this_mb = xr.open_dataset('./TMB/mb.nc')\
            .resample({'time':'YS'})\
            .sum()\
           .reindex(time=promice['time'])

# graphics
def my_plot(ax, x, err, **kw):

    p = ax.plot(x['time'], x.values, **kw)
    ax.fill_between(x['time'], x.values-err.values, x.values+err.values, **kw, alpha=0.5)

    if ax == axSMB:
        ax.set_title('SMB')
        ax.set_xlabel('[Gt yr$^{-1}$]')
        # ax.set_xlim([50,600])
        # ax.set_xlabel('C$_{2019}$ [Gt yr$^{-1}$]')
        # ax.set_ylabel('This [Gt yr$^{-1}$]')
    if ax == axD:
        ax.set_title('MMB [+ BMB]')
        # ax.set_xlim([350,500])
    if ax == axMB:
        ax.set_title('MB')
        # ax.set_xlim([-450,250])

    # ax.set_xticks(ax.get_xlim())
    # ax.set_ylim(ax.get_xlim())
    # ax.set_yticks(ax.get_xlim())
        
    # ax.plot(ax.get_xlim(), ax.get_ylim(), color='k', alpha=0.25, linestyle='--')
    adj(ax, ['left','bottom'])
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
    return p

kw_this = {'color': 'orange'}
kw_other = {'color': 'black'}
my_plot(axSMB, this_smb['MAR_sector'].sum(dim='sector'), this_smb['MAR_sector'].sum(dim='sector')*0.15, **kw_this)
my_plot(axSMB, promice['SMB'].sum(dim='sector'), promice['SMB_err'].sum(dim='sector'), **kw_other)

my_plot(axD, this_D['D_sector'].sum(dim='sector'), this_D['D_sector'].sum(dim='sector')*0.1, **kw_this)
my_plot(axD, promice['D'].sum(dim='sector'), promice['D_err'].sum(dim='sector'), **kw_other)

my_plot(axMB, this_mb['MAR_sector'].sum(dim='sector'), this_mb['MAR_sector'].sum(dim='sector')*0.15, **kw_this)
y = my_plot(axMB, promice['MB'].sum(dim='sector'), promice['MB_err'].sum(dim='sector'), **kw_other)

# # https://stackoverflow.com/questions/17478165/
# def axis_to_fig(axis):
#     fig = axis.figure
#     def transform(coord):
#         return fig.transFigure.inverted().transform(
#             axis.transAxes.transform(coord))
#     return transform

# def add_sub_axes(axis, rect):
#     fig = axis.figure
#     left, bottom, width, height = rect
#     trans = axis_to_fig(axis)
#     figleft, figbottom = trans((left, bottom))
#     figwidth, figheight = trans([width,height]) - trans([0,0])
#     return fig.add_axes([figleft, figbottom, figwidth, figheight])

# axCB = add_sub_axes(axMB, [1.1, 0.0, 0.075, 1])
# cb = plt.colorbar(s, cax=axCB, orientation='vertical', ticks=[0,1])
# cb.set_alpha(1) # https://stackoverflow.com/questions/4478725/
# cb.draw_all()
# # cb.set_label("Time [year]", labelpad=-20)
# axCB.set_yticklabels(promice['time'].dt.year[[0,-1]].values)

# plt.savefig('tmp/colgan_2019_ts.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:

[[./tmp/colgan_2019.png]]


** This vs. Mouginot (2019): regions xy

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
import matplotlib.gridspec as gridspec
import matplotlib.pyplot as plt
from matplotlib import rc
from adjust_spines import adjust_spines as adj
import scipy.stats as sps

rc('font', size=9)
rc('text', usetex=False)

# plt.close(1)
fig = plt.figure(1, figsize=((12/2.54),(22/2.54)*(7/8))) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# gs = gridspec.GridSpec(ncols=3, nrows=19, figure=fig) #w,h
gs = gridspec.GridSpec(ncols=3, nrows=7, figure=fig) #w,h

<<load_mouginot>>

# this
this_smb = xr.open_dataset('./tmp/smb.nc')\
             .resample({'time':'YS'})\
             .sum()

<<load_mmb>>
this_D = mmb.resample({'time':'YS'})\
            .sum()

this_mb = xr.open_dataset('./TMB/mb.nc')\
            .resample({'time':'YS'})\
            .sum()


mouginot = mouginot.where(mouginot['time'].dt.year >= 1987).dropna(dim='time')
this_smb = this_smb.where((this_smb['time'].dt.year <= 2018) & (this_smb['time'].dt.year >= 1987)).dropna(dim='time')
this_D = this_D.where((this_D['time'].dt.year <= 2018) & (this_D['time'].dt.year >= 1987)).dropna(dim='time')
this_mb = this_mb.where((this_mb['time'].dt.year <= 2018) & (this_mb['time'].dt.year >= 1987)).dropna(dim='time')

region = this_mb['region'].values

<<round_axes>>

def my_plot(ax, x, y):
    years = x.time.dt.year.values
    color = years - min(years); color = color / max(color)
    y2str = [_[2:4] for _ in years.astype(np.str)]

    # https://stackoverflow.com/questions/51034408/how-to-make-the-color-of-one-end-of-colorbar-darker-in-matplotlib
    cmap = cm.viridis(color)
    cmap = mpl.colors.ListedColormap(cmap[:-3,:-1])

    scatter = ax.scatter(x.values, y.values, alpha=0.75, c=color, cmap=cmap, clip_on=False)
        
    if x.region.values == 'NW':
        if ax == axSMB: ax.set_title('SMB')
        if ax == axD: ax.set_title('MMB + BMB')
        if ax == axMB: ax.set_title('MB')

    if (ax == axSMB):
        ax.set_ylabel(x.region.values)
        if (x.region.values == 'SE'):
            ax.set_xlabel('M$_{2019}$ [Gt yr$^{-1}$]')
            ax.set_ylabel(ax.get_ylabel() + '\nThis [Gt yr$^{-1}$]')


    ax.set_xticks(round_axes(ax.get_xlim(), ax.get_ylim()))
    ax.set_ylim(ax.get_xlim())
    ax.set_yticks(ax.get_xlim())
        
    slope, intercept, r_value, p_value, std_err = sps.linregress(x.values, y.values)
    # ax.plot(x, slope * x + intercept, 'k', linewidth=0.5)
    ax.text(0.66, 0,
            "s: %.1f\ni: %.1f" % (round(slope,1), round(intercept,1)),
            transform=ax.transAxes,
            fontsize=8)

    ax.plot(ax.get_xlim(), ax.get_ylim(), color='k', alpha=0.25, linestyle='--')
    adj(ax, ['left','bottom'])
    return scatter


# graphics
for i,region in enumerate(['NW','NO','NE','CW','CE','SW','SE']):
    axSMB = fig.add_subplot(gs[i,0])
    axD = fig.add_subplot(gs[i,1])
    axMB = fig.add_subplot(gs[i,2])

    my_plot(axSMB, mouginot['SMB'].sel({'region':region}), this_smb['MAR_region'].sel({'region':region}))
    my_plot(axD,   mouginot['D'].sel({'region':region}), this_D['D_region'].sel({'region':region}))
    s = my_plot(axMB,  mouginot['MB'].sel({'region':region}), this_mb['MAR_region'].sel({'region':region}))


# https://stackoverflow.com/questions/17478165/
def axis_to_fig(axis):
    fig = axis.figure
    def transform(coord):
        return fig.transFigure.inverted().transform(
            axis.transAxes.transform(coord))
    return transform

def add_sub_axes(axis, rect):
    fig = axis.figure
    left, bottom, width, height = rect
    trans = axis_to_fig(axis)
    figleft, figbottom = trans((left, bottom))
    figwidth, figheight = trans([width,height]) - trans([0,0])
    return fig.add_axes([figleft, figbottom, figwidth, figheight])

axCB = add_sub_axes(axD, [0, -1.1, 1, 0.1])
cb = plt.colorbar(s, cax=axCB, orientation='horizontal', ticks=[0,1])
cb.set_alpha(1) # https://stackoverflow.com/questions/4478725/
cb.draw_all()
axCB.set_xticklabels(this_mb['time'].dt.year[[0,-1]].values)
    
# plt.legend()
plt.savefig('tmp/mouginot_2019_regions.png', transparent=False, bbox_inches='tight', dpi=150)
#+END_SRC

#+RESULTS:
: <ipython-input-409-13697634a805>:194: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
:   plt.savefig('tmp/mouginot_2019_regions.png', transparent=False, bbox_inches='tight', dpi=150)

[[./tmp/colgan_2019_sectors.png]]

** This vs. Mouginot (2019): sector ts

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
import matplotlib.gridspec as gridspec

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=10)
rc('text', usetex=False)

fig = plt.figure(1, figsize=((12/2.54),23/2.54))
fig.clf()
fig.set_tight_layout(True)
gs = gridspec.GridSpec(ncols=3, nrows=8, figure=fig) #w,h


<<mouginot>>

# this
this_smb = xr.open_dataset('./tmp/smb.nc')\
             .resample({'time':'YS'})\
             .sum()

<<load_mmb>>
this_D = mmb.resample({'time':'YS'})\
            .sum()

this_mb = xr.open_dataset('./TMB/mb.nc')\
            .resample({'time':'YS'})\
            .sum()

<<round_axes>>

# graphics
def my_plot(ax, x, err, my_data=False, **kw):

    p = ax.plot(x['time'], x.values, **kw)
    ax.fill_between(x['time'], x.values-err.values, x.values+err.values, **kw, alpha=0.5)

    if my_data:
        ylim = round_axes(ax.get_ylim())
        ax.set_ylim(ylim)
        ax.set_xticks(ax.get_xlim())
        ax.get_xaxis().set_ticklabels(x.time.dt.year[[0,-1]].values)
        ax.get_xaxis().set_ticklabels(['',''])

        if x.region.values == 'NW':
            if ax == axSMB: ax.set_title('SMB')
            if ax == axD: ax.set_title('MMB + BMB')
            if ax == axMB: ax.set_title('MB')
            
        if (x.region.values == 'SW') & (ax == axD):
            ax.set_ylim([10,40])
        
        if (ax == axSMB):
            ax.set_ylabel(x.region.values)
            
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
        
        # ax.plot(ax.get_xlim(), ax.get_ylim(), color='k', alpha=0.25, linestyle='--')
        adj(ax, ['left','bottom'])
    return p

# graphics
for i,region in enumerate(['NW','NO','NE','CW','CE','SW','SE']):
    axSMB = fig.add_subplot(gs[i,0])
    axD = fig.add_subplot(gs[i,1])
    axMB = fig.add_subplot(gs[i,2])

    my_plot(axSMB, this_smb['MAR_region'].sel({'region':region}), this_smb['MAR_region'].sel({'region':region})*0.15, my_data=True, **kw_this)
    my_plot(axSMB, mouginot['SMB'].sel({'region':region}), mouginot['SMB_err'].sel({'region':region}), **kw_other)

    my_plot(axD, this_D['D_region'].sel({'region':region}), this_D['err_region'].sel({'region':region}), my_data=True, **kw_this)
    my_plot(axD, mouginot['D'].sel({'region':region}), mouginot['D_err'].sel({'region':region}), **kw_other)

    my_plot(axMB, this_mb['MAR_region'].sel({'region':region}), this_mb['MAR_region'].sel({'region':region})*0.33, my_data=True, **kw_this)
    my_plot(axMB, mouginot['MB'].sel({'region':region}), mouginot['MB_err'].sel({'region':region}), **kw_other)

axSMB = fig.add_subplot(gs[i+1,0])
axD = fig.add_subplot(gs[i+1,1])
axMB = fig.add_subplot(gs[i+1,2])

axSMB.plot(this_smb['time'], this_smb['MAR_region'].sum('region'), **kw_this)
axSMB.plot(mouginot['time'], mouginot['SMB'].sum('region'), **kw_other)

axD.plot(this_D['time'], this_D['D_region'].sum('region'), **kw_this)
axD.plot(mouginot['time'], mouginot['D'].sum('region'), **kw_other)

axMB.plot(this_mb['time'], this_mb['MAR_region'].sum('region'), **kw_this)
axMB.plot(mouginot['time'], mouginot['MB'].sum('region'), **kw_other)

axSMB.set_ylabel('GIS')

for ax in [axSMB, axD, axMB]:
    adj(ax, ['left','bottom'])
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
    ax.set_xticks(ax.get_xlim())
    ax.get_xaxis().set_ticklabels(this_mb.time.dt.year[[0,-1]].values)
    
plt.savefig('tmp/mouginot_2019_ts.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:

[[./tmp/colgan_2019.png]]


** This sector ts

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
import matplotlib.gridspec as gridspec

import matplotlib.pyplot as plt
from matplotlib import rc
rc('font', size=10)
rc('text', usetex=False)

fig = plt.figure(1, figsize=((12/2.54),23/2.54))
fig.clf()
fig.set_tight_layout(True)
gs = gridspec.GridSpec(ncols=1, nrows=8, figure=fig) #w,h

# this
this_smb = xr.open_dataset('./tmp/smb.nc')\
             .resample({'time':'YS'})\
             .sum()

<<load_mmb>>
this_D = mmb.resample({'time':'YS'})\
            .sum()

this_mb = xr.open_dataset('./TMB/mb.nc')\
            .resample({'time':'YS'})\
            .sum()

<<round_axes>>

# graphics
def my_plot(ax, x, err, **kw):

    ax.plot(x['time'], x.values, **kw)
    ax.fill_between(x['time'], x.values-err.values, x.values+err.values, **kw, alpha=0.5)

    # ylim = round_axes(ax.get_ylim())
    # ax.set_ylim([-100, ylim[1]])
    ax.set_xticks(ax.get_xlim())
    ax.get_xaxis().set_ticklabels(x.time.dt.year[[0,-1]].values)
    ax.get_xaxis().set_ticklabels(['',''])
    ax.set_ylabel(x.region.values)
            
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
    adj(ax, ['left','bottom'])

for i,region in enumerate(['NW','NO','NE','CW','CE','SW','SE']):
    ax = fig.add_subplot(gs[i,0])

    my_plot(ax, this_smb['MAR_region'].sel({'region':region}), this_smb['MAR_region'].sel({'region':region})*0.15, color='gray')
    my_plot(ax, -this_D['D_region'].sel({'region':region}), this_D['err_region'].sel({'region':region}), color='blue')
    my_plot(ax, this_mb['MAR_region'].sel({'region':region}), this_mb['MAR_region'].sel({'region':region})*0.33, color='black')

ax = fig.add_subplot(gs[i+1,0])
ax.plot(this_smb['time'], this_smb['MAR_region'].sum('region'), color='gray', label='SMB')
ax.plot(this_D['time'], -this_D['D_region'].sum('region'), color='blue', label='MMB')
ax.plot(this_mb['time'], this_mb['MAR_region'].sum('region'), color='black', label='MB')
ax.set_ylabel('GIS\n[Gt yr$^{-1}$]')
ax.legend(fontsize=8, ncol=1, loc=(0.30, -1.1), fancybox=True, frameon=True)

adj(ax, ['left','bottom'])
plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
ax.set_xticks(ax.get_xlim())
ax.get_xaxis().set_ticklabels(this_mb.time.dt.year[[0,-1]].values)
    
plt.savefig('tmp/sector_ts.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:


** NOTDONE This vs. Colgan (2019): 3D

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)

# plt.close(1)
fig = plt.figure(1, figsize=(8,2.5)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
ax = fig.add_subplot(111, projection='3d')

# PROMICE MB (Colgan 2019)
<<load_PROMICE_MB>>

# this
this_smb = xr.open_dataset('./tmp/smb.nc')\
             .resample({'time':'YS'})\
             .sum()\
             .reindex(time=promice['time'])

<<load_mmb>>
this_D = mmb.resample({'time':'YS'})\
            .sum()\
            .reindex(time=promice['time'])

this_mb = xr.open_dataset('./TMB/mb.nc')\
            .resample({'time':'YS'})\
            .sum()\
           .reindex(time=promice['time'])

# graphics
x = this_smb['MAR_sector'].sum(dim='sector').values
x = this_D['D_sector'].sum(dim='sector').values
y = this_mb['MAR_sector'].sum(dim='sector').values

ax.plot(x, y, z, zdir='z')
ax.plot(x, z, zdir='y', zs=ax.get_ylim()[1])
ax.plot(y, z, zdir='x', zs=ax.get_xlim()[0])
ax.plot(x, y, zdir='z', zs=ax.get_zlim()[0])

ax.set_xlabel('SMB')
ax.set_ylabel('D')
ax.set_zlabel('MB')

plt.savefig('tmp/colgan_2019_3d.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:
: (-435.61391955729334, 250.0439373209448)

[[./tmp/colgan_2019_3d.png]]
** NOTDONE This: SMB MMB MB bar chart

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import pandas as pd
import matplotlib.gridspec as gridspec
import matplotlib.pyplot as plt
from matplotlib import rc
from adjust_spines import adjust_spines as adj
import scipy as sp
import scipy.stats as sps

rc('font', size=9)
rc('text', usetex=False)

# plt.close(1)
fig = plt.figure(1, figsize=((12/2.54),(22/2.54))) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# gs = gridspec.GridSpec(ncols=3, nrows=19, figure=fig) #w,h
gs = gridspec.GridSpec(ncols=3, nrows=8, figure=fig) #w,h

# this
this_smb = xr.open_dataset('./tmp/smb.nc')\
             .resample({'time':'YS'})\
             .sum()\
             .reindex(time=promice['time'])

<<load_mmb>>
this_D = mmb.resample({'time':'YS'})\
            .sum()\
            .reindex(time=promice['time'])

this_mb = xr.open_dataset('./TMB/mb.nc')\
            .resample({'time':'YS'})\
            .sum()\
            .reindex(time=promice['time'])


# collapse all Wally sectors to just super-sectors
this_smb['Z'] = (('sector'), (this_smb.sector.values/10).astype(np.int))
this_smb = this_smb.groupby('Z').sum().rename({'Z':'sector'})
this_D['Z'] = (('sector'), (this_D.sector.values/10).astype(np.int))
this_D = this_D.groupby('Z').sum().rename({'Z':'sector'})
this_mb['Z'] = (('sector'), (this_mb.sector.values/10).astype(np.int))
this_mb = this_mb.groupby('Z').sum().rename({'Z':'sector'})

sector = this_mb['sector']

<<round_axes>>

xpos = [i for i,_ in enumerate(this_smb.sector)]
plt.bar(this_smb['time'], xpos, this_smb.sector, this_smb

# def my_plot(ax, x, y):
#     years = x.time.dt.year.values
#     color = years - min(years); color = color / max(color)
#     y2str = [_[2:4] for _ in years.astype(np.str)]

#     # https://stackoverflow.com/questions/51034408/how-to-make-the-color-of-one-end-of-colorbar-darker-in-matplotlib
#     cmap = cm.viridis(color)
#     cmap = mpl.colors.ListedColormap(cmap[:-3,:-1])

#     scatter = ax.scatter(x.values, y.values, alpha=0.75, c=color, cmap=cmap, clip_on=False)
        
#     if x.sector.values == 1:
#         if ax == axSMB: ax.set_title('SMB')
#         if ax == axD: ax.set_title('MMB + BMB')
#         if ax == axMB: ax.set_title('MB')

#     if (ax == axSMB):
#         ax.set_ylabel(x.sector.values)
#         if (x.sector.values == 8):
#             ax.set_xlabel('C$_{2019}$ [Gt yr$^{-1}$]')
#             ax.set_ylabel(ax.get_ylabel() + '\nThis [Gt yr$^{-1}$]')

#     slope, intercept, r_value, p_value, std_err = sps.linregress(x.values, y.values)
#     # ax.plot(x, slope * x + intercept, 'k', linewidth=0.5)
#     ax.text(0.66, 0,
#             "s: %.1f\ni: %.1f" % (round(slope,1), round(intercept,1)),
#             transform=ax.transAxes,
#             fontsize=8)

#     ax.set_xticks(round_axes(ax.get_xlim(), ax.get_ylim()))
#     ax.set_ylim(ax.get_xlim())
#     ax.set_yticks(ax.get_xlim())
        
#     ax.plot(ax.get_xlim(), ax.get_ylim(), color='k', alpha=0.25, linestyle='--')
#     adj(ax, ['left','bottom'])
#     return scatter


# # graphics
# for row in np.arange(8):
#     axSMB = fig.add_subplot(gs[row,0])
#     axD = fig.add_subplot(gs[row,1])
#     axMB = fig.add_subplot(gs[row,2])

#     my_plot(axSMB,
#             promice['SMB'].sel({'sector':sector[row]}),
#             this_smb['MAR_sector'].sel({'sector':sector[row]}))
    

#     if (sector[row] != 14) & (sector[row] != 22):
#         my_plot(axD,
#                 promice['D'].sel({'sector':sector[row]}),
#                 this_D['D_sector'].sel({'sector':sector[row]}))

#     s = my_plot(axMB,
#                 promice['MB'].sel({'sector':sector[row]}),
#                 this_mb['MAR_sector'].sel({'sector':sector[row]}))

# # https://stackoverflow.com/questions/17478165/
# def axis_to_fig(axis):
#     fig = axis.figure
#     def transform(coord):
#         return fig.transFigure.inverted().transform(
#             axis.transAxes.transform(coord))
#     return transform

# def add_sub_axes(axis, rect):
#     fig = axis.figure
#     left, bottom, width, height = rect
#     trans = axis_to_fig(axis)
#     figleft, figbottom = trans((left, bottom))
#     figwidth, figheight = trans([width,height]) - trans([0,0])
#     return fig.add_axes([figleft, figbottom, figwidth, figheight])

# axCB = add_sub_axes(axD, [0, -1, 1, 0.1])
# cb = plt.colorbar(s, cax=axCB, orientation='horizontal', ticks=[0,1])
# cb.set_alpha(1) # https://stackoverflow.com/questions/4478725/
# cb.draw_all()
# axCB.set_xticklabels(promice['time'].dt.year[[0,-1]].values)
    
# # plt.legend()
# plt.savefig('tmp/sector_bars.png', transparent=False, bbox_inches='tight', dpi=150)
#+END_SRC

#+RESULTS:


** CRediT

#+NAME: tbl_credit
| Task                        | KDM | RSF | APA | BN | XF | PL | MS | ASO | SIBA | NBK | WIC | MK |
| Conceptualization           |   2 |   2 |     |    |    |    |    |     |      |     |     |    |
| Data curation               |   3 |     |     |  3 |  3 |  3 |  3 |   3 |      |     |     |    |
| Formal analysis: Sector SMB |     |     |     |    |    |    |    |     |      |     |     |    |
| Formal analysis: Future MMB |     |     |     |    |    |    |    |     |      |     |     |  3 |
| Funding acquisition         |   1 |   3 |   3 |    |    |    |    |   3 |    2 |     |     |    |
| Investigation               |     |     |     |    |    |    |    |     |      |     |     |    |
| Methods: SMB                |     |     |     |  3 |  3 |  3 |  3 |     |      |     |     |    |
| Methods: MMB                |   3 |   1 |   1 |    |    |    |    |     |      |     |     |    |
| Methods: BMB                |     |     |     |    |    |    |    |     |      |     |     |    |
| Methods: GRACE compare      |     |     |     |    |    |    |    |     |      |     |   3 |    |
| Project administration      |   3 |   1 |   1 |    |    |    |    |     |    1 |     |     |    |
| Resources                   |   2 |     |     |  2 |  2 |    |  2 |     |    2 |     |     |    |
| Software                    |   3 |     |     |    |    |    |    |     |      |     |     |    |
| Supervision                 |     |     |     |    |    |    |    |     |      |     |     |    |
| Validation                  |   3 |     |     |    |    |    |    |     |      |     |     |    |
| Visualization               |   3 |     |     |    |    |    |    |     |      |     |     |    |
| Writing (First draft)       |   3 |     |     |    |    |    |    |     |      |     |     |    |
| Writing (Editing)           |   3 |     |     |    |    |    |    |     |      |     |     |    |


#+BEGIN_SRC python :var tbl=tbl_credit :session :exports none
import pandas as pd
df = pd.DataFrame(index = [_[0] for _ in tbl[1:]],
                  columns = tbl[0][1:],
                  data = np.array(tbl)[1:,1:])
df = df.apply(pd.to_numeric)
df.to_csv('./tmp/credit.csv')
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC jupyter-python
import seaborn as sns
import numpy as np
import pandas as pd
from matplotlib.colors import LinearSegmentedColormap
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)

cmap = sns.color_palette("Blues", 3)

fig = plt.figure(1, figsize=(5,4)) # w,h
fig.clf()
fig.set_tight_layout(True)
ax = fig.add_subplot(111)

df = pd.read_csv('./tmp/credit.csv', index_col=0)

fig = plt.figure(1, figsize=(8,6)) # w,h
fig.clf()
fig.set_tight_layout(True)
ax = fig.add_subplot(111)

sns.set()

im = sns.heatmap(df, vmin=1, vmax=3, cmap = cmap, fmt='d', ax=ax)

plt.xticks(rotation=-90)

# Manually specify colorbar labelling after it's been generated
colorbar = ax.collections[0].colorbar
colorbar.set_ticks([1.33, 2, 2.66])
colorbar.set_ticklabels(['1', '2', '3'])
colorbar.set_label('Contribution')

ax.set_ylabel('What')
ax.set_xlabel('Who')

plt.savefig('./fig/credit.png', transparent=False, bbox_inches='tight', dpi=150)
#+END_SRC

#+RESULTS:


* Helper functions
** Imports

#+NAME: py_import
#+BEGIN_SRC jupyter-python
import numpy as np
import xarray as xr
import datetime
import pandas as pd
#+END_SRC

** Adjust Spines

#+BEGIN_SRC jupyter-python :tangle adjust_spines.py
# http://matplotlib.org/examples/pylab_examples/spine_placement_demo.html
def adjust_spines(ax,spines, offset=10):
    for loc, spine in ax.spines.items():
        if loc in spines:
            spine.set_position(('outward', offset)) # outward
            # by 10 points
            #spine.set_smart_bounds(True)
        else:
            spine.set_color('none') # don't
            # draw spine

        # turn off ticks where there
        # is no spine
        if 'left' in spines:
            ax.yaxis.set_tick_params(length=5)
            ax.yaxis.set_tick_params(direction='out')
            ax.yaxis.set_ticks_position('left')
            ax.yaxis.set_label_position('left')
        elif 'right' in spines:
            ax.yaxis.set_tick_params(length=5)
            ax.yaxis.set_tick_params(direction='out')
            ax.yaxis.set_ticks_position('right')
            ax.yaxis.set_label_position('right')
        else:
            # no yaxis ticks
            ax.yaxis.set_ticks([])

        if 'bottom' in spines:
            ax.xaxis.set_ticks_position('bottom')
            ax.xaxis.set_tick_params(length=5)
            ax.xaxis.set_tick_params(direction='out')
            ax.xaxis.set_label_position('bottom')
        elif 'top' in spines:
            ax.xaxis.set_ticks_position('top')
            ax.xaxis.set_tick_params(length=5)
            ax.xaxis.set_tick_params(direction='out')
            ax.xaxis.set_label_position('top')
        else:
            # no xaxis
            # ticks
            ax.xaxis.set_ticks([])


if __name__ == "__main__":
    import numpy as np            
    x = np.random.random(100)
    fig = plt.figure(100)
    fig.clf()
    ax = fig.add_axes([0.1,0.1,0.8,0.8])
    ax.plot(x)
    adjust_spines(ax,["left","bottom"])

#+END_SRC

** round axes
#+NAME: round_axes
#+BEGIN_SRC jupyter-python
def round_axes(x, y=None):
    x = np.append(x,y) if y is not None else np.array(x)
    # print(x)
    mmin = np.min(x)
    mmax = np.max(x)
    sign = np.sign([mmin,mmax])
    # mmin = 10**np.floor(np.log10(sign[0]*mmin*10)) * sign[0]
    # mmax = 10**np.ceil(np.log10(sign[1]*mmax/10)) * sign[1]
    mmin = np.floor(mmin/10)*10
    mmax = np.ceil(mmax/10)*10
    return(mmin,mmax)
#+END_SRC

** cron jobs
*** HIRHAM

Run with =0 5 * * * ~/bin/HIRHAM_daily.sh=

# #+HEADER: :tangle ~/bin/HIRHAM_daily.sh
#+BEGIN_SRC bash 
#!/bin/bash

cd ~/data/HIRHAM/
wget -a ~/data/HIRHAM/wget.log --user MB --password <PW> -np -nc ftp.dmi.dk:KDM_SMB_files/*
#+END_SRC

*** MAR

Run with =0 5 * * * ~/bin/MAR_daily.sh=

# #+HEADER: :tangle ~/bin/MAR_daily.sh
#+BEGIN_SRC bash 
#!/bin/bash

cd ~/data/MAR/
wget -a ~/data/MAR/wget.log -np -nc ftp://ftp.climato.be/fettweis/MARv3.11/Greenland/NCEP1_1948-2020_20km/MARv3.11-20km-daily-NCEP-NCARv1-2021.nc -o ./daily/MARv3.11-20km-daily-NCEP-NCARv1-2021.nc
#+END_SRC


* Environment
** Python
*** Anaconda environment

**** Create
#+BEGIN_SRC bash
env=TMB
conda create -n ${env} python=3.8 xarray pandas matplotlib jupyter tabulate pint uncertainties scipy cfchecker geopandas
conda activate ${env}
python -m ipykernel install --user --name=${env}

# anconda install matplotlib xarray rasterio simplekml 
# pip install uncertainties

#+END_SRC
**** Share

#+BEGIN_SRC bash :cmdline -i :results drawer verbatim :exports both
conda env export --name TMB | tee environment.yml
#+END_SRC

#+RESULTS:
:results:
name: TMB
channels:
  - conda-forge
  - defaults
dependencies:
  - _libgcc_mutex=0.1=conda_forge
  - _openmp_mutex=4.5=1_gnu
  - argon2-cffi=20.1.0=py38h25fe258_2
  - async_generator=1.10=py_0
  - attrs=20.3.0=pyhd3deb0d_0
  - backcall=0.2.0=pyh9f0ad1d_0
  - backports=1.0=py_2
  - backports.functools_lru_cache=1.6.1=py_0
  - bleach=3.2.1=pyh9f0ad1d_0
  - bzip2=1.0.8=h516909a_3
  - c-ares=1.16.1=h516909a_3
  - ca-certificates=2020.11.8=ha878542_0
  - certifi=2020.11.8=py38h578d9bd_0
  - cfchecker=4.0.0=py_0
  - cffi=1.14.3=py38h1bdcb99_1
  - cftime=1.3.0=py38h0b5ebd8_0
  - cfunits=3.3.0=pyh9f0ad1d_0
  - curl=7.71.1=he644dc0_8
  - cycler=0.10.0=py_2
  - dbus=1.13.6=hfdff14a_1
  - decorator=4.4.2=py_0
  - defusedxml=0.6.0=py_0
  - entrypoints=0.3=pyhd8ed1ab_1003
  - expat=2.2.9=he1b5a44_2
  - fontconfig=2.13.1=h7e3eb15_1002
  - freetype=2.10.4=h7ca028e_0
  - future=0.18.2=py38h578d9bd_2
  - gettext=0.19.8.1=hf34092f_1004
  - glib=2.66.2=h58526e2_0
  - gst-plugins-base=1.14.5=h0935bb2_2
  - gstreamer=1.14.5=h36ae1b5_2
  - hdf4=4.2.13=hf30be14_1003
  - hdf5=1.10.6=nompi_h1022a3e_1110
  - icu=67.1=he1b5a44_0
  - importlib-metadata=2.0.0=py_1
  - importlib_metadata=2.0.0=1
  - importlib_resources=3.3.0=py38h578d9bd_0
  - ipykernel=5.3.4=py38h81c977d_1
  - ipython=7.19.0=py38h81c977d_0
  - ipython_genutils=0.2.0=py_1
  - ipywidgets=7.5.1=pyh9f0ad1d_1
  - jedi=0.17.2=py38h578d9bd_1
  - jinja2=2.11.2=pyh9f0ad1d_0
  - jpeg=9d=h36c2ea0_0
  - jsonschema=3.2.0=py_2
  - jupyter=1.0.0=py_2
  - jupyter_client=6.1.7=py_0
  - jupyter_console=6.2.0=py_0
  - jupyter_core=4.6.3=py38h578d9bd_2
  - jupyterlab_pygments=0.1.2=pyh9f0ad1d_0
  - kiwisolver=1.3.1=py38h82cb98a_0
  - krb5=1.17.1=hfafb76e_3
  - lcms2=2.11=hcbb858e_1
  - ld_impl_linux-64=2.35.1=hed1e6ac_0
  - libblas=3.9.0=2_openblas
  - libcblas=3.9.0=2_openblas
  - libclang=10.0.1=default_hde54327_1
  - libcurl=7.71.1=hcdd3856_8
  - libedit=3.1.20191231=he28a2e2_2
  - libev=4.33=h516909a_1
  - libevent=2.1.10=hcdb4288_3
  - libffi=3.2.1=he1b5a44_1007
  - libgcc-ng=9.3.0=h5dbcf3e_17
  - libgfortran-ng=9.3.0=he4bcb1c_17
  - libgfortran5=9.3.0=he4bcb1c_17
  - libglib=2.66.2=hbe7bbb4_0
  - libgomp=9.3.0=h5dbcf3e_17
  - libiconv=1.16=h516909a_0
  - liblapack=3.9.0=2_openblas
  - libllvm10=10.0.1=he513fc3_3
  - libnetcdf=4.7.4=nompi_hefab0ff_106
  - libnghttp2=1.41.0=h8cfc5f6_2
  - libopenblas=0.3.12=pthreads_h4812303_1
  - libpng=1.6.37=h21135ba_2
  - libpq=12.3=h5513abc_2
  - libsodium=1.0.18=h36c2ea0_1
  - libssh2=1.9.0=hab1572f_5
  - libstdcxx-ng=9.3.0=h2ae2ef3_17
  - libtiff=4.1.0=h4f3a223_6
  - libuuid=2.32.1=h14c3975_1000
  - libwebp-base=1.1.0=h36c2ea0_3
  - libxcb=1.13=h14c3975_1002
  - libxkbcommon=0.10.0=he1b5a44_0
  - libxml2=2.9.10=h68273f3_2
  - lz4-c=1.9.2=he1b5a44_3
  - markupsafe=1.1.1=py38h8df0ef7_2
  - matplotlib=3.3.3=py38h578d9bd_0
  - matplotlib-base=3.3.3=py38h5c7f4ab_0
  - mistune=0.8.4=py38h25fe258_1002
  - mysql-common=8.0.21=2
  - mysql-libs=8.0.21=hf3661c5_2
  - nbclient=0.5.1=py_0
  - nbconvert=6.0.7=py38h578d9bd_3
  - nbformat=5.0.8=py_0
  - ncurses=6.2=h58526e2_4
  - nest-asyncio=1.4.3=pyhd8ed1ab_0
  - netcdf4=1.5.4=nompi_py38hec8b9af_103
  - notebook=6.1.5=py38h578d9bd_0
  - nspr=4.29=he1b5a44_1
  - nss=3.59=h2c00c37_0
  - numpy=1.19.4=py38hf0fd68c_1
  - olefile=0.46=pyh9f0ad1d_1
  - openssl=1.1.1h=h516909a_0
  - packaging=20.4=pyh9f0ad1d_0
  - pandas=1.1.4=py38h0ef3d22_0
  - pandoc=2.11.1.1=h36c2ea0_0
  - pandocfilters=1.4.2=py_1
  - parso=0.7.1=pyh9f0ad1d_0
  - pcre=8.44=he1b5a44_0
  - pexpect=4.8.0=pyh9f0ad1d_2
  - pickleshare=0.7.5=py_1003
  - pillow=8.0.1=py38h70fbd49_0
  - pint=0.16.1=py_0
  - pip=20.2.4=py_0
  - prometheus_client=0.9.0=pyhd3deb0d_0
  - prompt-toolkit=3.0.8=pyha770c72_0
  - prompt_toolkit=3.0.8=hd8ed1ab_0
  - pthread-stubs=0.4=h14c3975_1001
  - ptyprocess=0.6.0=py_1001
  - pycparser=2.20=pyh9f0ad1d_2
  - pygments=2.7.2=py_0
  - pyparsing=2.4.7=pyh9f0ad1d_0
  - pyqt=5.12.3=py38ha8c2ead_4
  - pyrsistent=0.17.3=py38h25fe258_1
  - python=3.8.6=h852b56e_0_cpython
  - python-dateutil=2.8.1=py_0
  - python_abi=3.8=1_cp38
  - pytz=2020.4=pyhd8ed1ab_0
  - pyzmq=20.0.0=py38h1d1b12f_1
  - qt=5.12.9=h1f2b2cb_0
  - qtconsole=4.7.7=pyh9f0ad1d_0
  - qtpy=1.9.0=py_0
  - readline=8.0=he28a2e2_2
  - scipy=1.5.3=py38hb2138dd_0
  - send2trash=1.5.0=py_0
  - setuptools=49.6.0=py38h924ce5b_2
  - six=1.15.0=pyh9f0ad1d_0
  - sqlite=3.33.0=h4cf870e_1
  - tabulate=0.8.7=pyh9f0ad1d_0
  - terminado=0.9.1=py38h32f6830_1
  - testpath=0.4.4=py_0
  - tk=8.6.10=hed695b0_1
  - tornado=6.1=py38h25fe258_0
  - traitlets=5.0.5=py_0
  - udunits2=2.2.27.6=h4e0c4b3_1001
  - uncertainties=3.1.4=py_0
  - wcwidth=0.2.5=pyh9f0ad1d_2
  - webencodings=0.5.1=py_1
  - wheel=0.35.1=pyh9f0ad1d_0
  - widgetsnbextension=3.5.1=py38h578d9bd_4
  - xarray=0.16.1=py_0
  - xorg-libxau=1.0.9=h14c3975_0
  - xorg-libxdmcp=1.1.3=h516909a_0
  - xz=5.2.5=h516909a_1
  - zeromq=4.3.3=h58526e2_2
  - zipp=3.4.0=py_0
  - zlib=1.2.11=h516909a_1010
  - zstd=1.4.5=h6597ccf_2
  - pip:
    - pyqt5-sip==4.19.18
    - pyqtchart==5.12
    - pyqtwebengine==5.12.1
prefix: /home/kdm/local/miniconda3/envs/TMB

:end:

*** Packages
#+NAME: init_py
#+BEGIN_SRC jupyter-python
import numpy as np
import pandas as pd
import xarray as xr
#+END_SRC

#+RESULTS: init

*** Graphics
#+NAME: init_graphics
#+BEGIN_SRC jupyter-python
import matplotlib.pyplot as plt

from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)
matplotlib.pyplot.xkcd()
#+END_SRC

#+RESULTS: init_graphics

*** Data Dir

+ I set =DATADIR= as a =bash= environment variable in my login scripts.
+ This is so that Python babel blocks can also easily get that property.

#+NAME: get_DATADIR
#+BEGIN_SRC jupyter-python
import os
DATADIR = os.environ['DATADIR']
#+END_SRC

Example:
#+BEGIN_SRC jupyter-python :tangle no
<<get_DATADIR>>
print(DATADIR)
#+END_SRC

** Bash
#+NAME: init_bash
#+BEGIN_SRC bash :results verbatim
set -o nounset
set -o pipefail

# set -o errexit

### uncomment the above line when doing initial run. When rerunning and
### counting on GRASS failing w/ overwrite issues (speed increase), the
### line above must be commented

red='\033[0;31m'; orange='\033[0;33m'; green='\033[0;32m'; nc='\033[0m' # No Color
log_info() { echo -e "${green}[$(date --iso-8601=seconds)] [INFO] ${@}${nc}"; }
log_warn() { echo -e "${orange}[$(date --iso-8601=seconds)] [WARN] ${@}${nc}"; }
log_err() { echo -e "${red}[$(date --iso-8601=seconds)] [ERR] ${@}${nc}" >&2; }

# trap ctrl_c INT # trap ctrl-c and call ctrl_c()
# ctrl_c() { log_err "CTRL-C. Cleaning up"; }

debug() { if [[ debug:- == 1 ]]; then log_warn "debug:"; echo $@; fi; }

#+END_SRC

** GRASS config

https://grass.osgeo.org/grass74/manuals/variables.html

| GRASS_VERBOSE |                                                                |
|---------------+----------------------------------------------------------------|
|            -1 | complete silence (also errors and warnings are discarded)      |
|             0 | only errors and warnings are printed                           |
|             1 | progress and important messages are printed (percent complete) |
|             2 | all module messages are printed                                |
|             3 | additional verbose messages are printed                        |

#+NAME: init_grass
#+BEGIN_SRC bash :results verbatim :tangle no
export GRASS_VERBOSE=3
# export GRASS_MESSAGE_FORMAT=silent

if [ -z ${DATADIR+x} ]; then
    echo "DATADIR environment varible is unset."
    echo "Fix with: \"export DATADIR=/path/to/data\""
    exit 255
fi

set -x # print commands to STDOUT before running them
#+END_SRC

* Makefile
:PROPERTIES:
:CUSTOM_ID: sec:makefile
:END:

This code, and all code files in this project, are derived products tangled from the sob.org source file.

#+BEGIN_SRC makefile :tangle Makefile :tangle-mode (identity #o444)
PROMICE_MB: all
# dist

all: FORCE
	mkdir -p tmp dat

	# set up
	grass -e -c EPSG:4326 G_HIRHAM
	grass ./G_HIRHAM/PERMANENT/ --exec ./HIRHAM.sh
	
	grass -c ./G_MAR --exec ./MAR.sh

	grass -e -c EPSG:3413 G_RACMO
	grass ./G_RACMO/PERMANENT --exec ./RACMO.sh
	
	make SMB
	make BMB
	make dist

SMB: FORCE
	# partition RCM by Zwally sectors, Mouginot basins, and Mouginot regions
	grass ./G_HIRHAM/PERMANENT --exec ./SMB_HIRHAM_ROI.sh
	grass ./G_MAR/PERMANENT --exec ./SMB_MAR_ROI.sh
	grass ./G_RACMO/PERMANENT --exec ./SMB_RACMO_ROI.sh
	./smb_merge.sh
	python ./smb_bsv2nc.py

BMB: FORCE
	grass -e -c EPSG:3413 ./G_BMB
	grass ./G_BMB/PERMANENT --exec ./BMB.sh
	grass ./G_MAR/PERMANENT --exec ./BMB_MAR.sh
	./bmb_merge.sh
	python ./bmb_bsv2nc.py

test:
	python ./smb_bsv2nc.py
	python ./build_TMB_nc.py
	python ./fig_compare.py
	
	
validate: FORCE
	grass -e -c EPSG:3413 G
#	# python ./SEC_prep.py
	grass ./G/PERMANENT/ --exec ./SEC.sh
#	# grass ./G/PERMANENT/ --exec ./GRACE.sh
	
dist: FORCE
	# create end-user data product
	# parallel --bar "python bsv2netcdf.py {}" ::: $(ls dat/*_runoff_*.bsv)
# dist: freshwater.zip
# 	zip -r freshwater.zip freshwater

FORCE: # dummy target

clean_all:
	rm -fR G G_RACMO G_HIRHAM G_MAR G_tmp tmp dat PROMICE_MB G_BMB

clean_SMB:
	rm -fR tmp/HIRHAM tmp/MAR tmp/RACMO 
	
#+END_SRC


* Testing
** NOTDONE Compare annual RACMO to HIRHAM 
*** MAR

See above

*** HIRHAM annual

#+BEGIN_SRC bash
cd ${DATADIR}/HIRHAM/daily/
mkdir ann
# cdo yearsum DarcySensitivity_RP810_Daily2D_GL2LIN_Darcy_60m_liqCL_wh1_smb_HydroYr_1999_2000_DM_SD.nc ./ann/1999.nc
parallel --progress --bar "cdo timsum \"*{1}_????_DM_SD.nc\" ./ann/{1}.nc" ::: $(seq 1986 2016)
#+END_SRC




*** Compare

#+BEGIN_SRC jupyter-python
import pandas as pd
import xarray as xr

# for masks
era0 = xr.open_dataset('/home/kdm/data/MAR/daily2/MARv3.11.5-20km-daily-ERA5-2000.nc')
era = xr.open_mfdataset('/home/kdm/data/MAR/daily2/ann/*.nc', combine='by_coords').squeeze()
era_mask = era.where(era0['MSK'] > 50)
era_sum = era_mask.sum(dim=['X12_84','Y21_155'])

era = pd.DataFrame(era_sum['SMB'].to_dataframe()['SMB']).rename(columns={'SMB':'MAR'})
era.index = pd.to_datetime(era.index.year, format='%Y')

h = xr.open_mfdataset('/home/kdm/data/HIRHAM/daily/ann/*.nc', combine='by_coords')\
      .squeeze()\
      .sum(dim=['x','y'])

h = pd.DataFrame(h.to_dataframe()['smb']).rename(columns={'smb':'HIRHAM'})
h.index = pd.to_datetime(h.index.year, format='%Y')

df = era
df = df.merge(h/10, left_index=True, right_index=True)
# df = df.merge(h.to_dataframe()['smb'], left_index=True, right_index=True).rename(columns={'smb':'HIRHAM'})
df.plot(drawstyle='steps')
#+END_SRC

#+RESULTS:
: <AxesSubplot:>
